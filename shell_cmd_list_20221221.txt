Shell 可以看作是一个命令解释器，为我们提供了交互式的文本控制台界面。
我们可以通过终端控制台来输入命令，由 shell 进行解释并最终交给内核执行。

常用基础快捷键
ctrl+c 停止进程 (不想修改想结束本行重新输入，可以使用该命令直接跳到下一行;输入错误无法结束该命令也可使用该命令强制结束)
ctrl+l 清屏，等同于clear；彻底清屏是：reset
tab 键 提示(更重要的是可以防止敲错) 自动补全
上下键 查找执行过的命令

--以下要配合鼠标使用 也是在Xshell中的命令
ctrl+insert   复制
shift+insert  粘贴
ctrl+shift+f  查找 (在查找一个页面有什么时候很实用)

--------------------------- <-->01.帮助类命令------------------------
<-->1.man 获得帮助信息
基本语法
man [命令或配置文件] （功能描述：获得帮助信息）

[zhangjian@hadoop102 ~]$ man ls

<-->2.help 获得 shell 内置命令的帮助信息
一部分基础功能的系统命令是直接内嵌在 shell 中的，系统加载启动之后会随着shell 一起加载，常驻系统内存中。
这部分命令被称为“内置（built-in）命令”；相应的其它命令被称为“外部命令”。
基本语法
help 命令（功能描述：获得 shell 内置命令的帮助信息）
案例实操
（1）查看 cd 命令的帮助信息
[root@hadoop101 ~]# help cd

--------------------------- $#02.文件目录类命令---------------------
<-->3.pwd 显示当前工作目录的绝对路径

<-->4.ls 列出目录的内容

1）基本语法
ls [选项] [目录或是文件]

2）常用选项说明
选项 功能
-a 全部的文件，连同隐藏档( 开头为 . 的文件) 一起列出来(常用) 
-l 长数据串列出，包含文件的属性与权限等等数据；(常用)等价于“ll”3）
-R     递归列出遇到的子目录 (子目录少时可以查看使用，不要对大文件使用否则会跳出很多内容)
-c     使用“状态改变时间”代替“文件修改时间”为依据来排序 （使用“ -t ”选项时）或列出（使用“ -l ”选项时）
-t     按时间信息排序

-l, --format=long, --format=verbose
          除每个文件名外，增加显示文件类型、权限、硬链接数、所有者名、组名、大小（byte）、及时间信息（如未指明是
          其它时间即指修改时间）。对于6个月以上的文件或超出未来 1 小时的文件，时间信息中的时分将被年代取代。

          每个目录列出前，有一行“总块数”显示目录下全部文件所占的磁盘空间。块默认是1024字节；如果设置了POSIXLY_CORRECT
          的环境变量，除非用“-k”选项，则默认块大小是512字节。每一个硬链接都计入总块数（因此可能重复计数），这无
          疑是个缺点。
		  
-F, --classify, --file-type
          在每个文件名后附上一个字符以说明该文件的类型。
		  “ * ”表示普通的可执行文件； 
		  “ / ”表示目录；
		  “ @ ”表示符号链接；
		  “ | ”表示FIFOs；
		  “ = ”表示套接字 (sockets) ；
		  什么也没有则表示普通文件。
		  
-L, --dereference
          列出符号链接指向的文件的信息，而不是符号链接本身
		  
-S, --sort=size
          按文件大小而不是字典序排序目录内容，大文件靠前。

3）使用案例

[zhangjian@hadoop102 module]$ ls -t
db_log  applog  miniconda3  azkaban  spark  hive  sqoop  flume  kafka  zookeeper-3.5.7  hadoop-3.1.3  jdk1.8.0_212

[zhangjian@hadoop102 module]$ ls -lt
总用量 4
drwxrwxr-x.  2 zhangjian zhangjian   76 9月  23 2021 db_log
drwxrwxr-x.  3 zhangjian zhangjian  117 9月  23 2021 applog
drwxrwxr-x. 15 zhangjian zhangjian  226 9月  20 2021 miniconda3
drwxrwxr-x.  5 zhangjian zhangjian   70 9月  20 2021 azkaban
drwxr-xr-x. 15 zhangjian zhangjian  235 9月  10 2021 spark
drwxrwxr-x.  9 zhangjian zhangjian  153 9月   6 2021 hive
drwxr-xr-x.  9 zhangjian zhangjian 4096 9月   5 2021 sqoop
drwxrwxr-x.  7 zhangjian zhangjian  232 9月   4 2021 flume
drwxr-xr-x.  8 zhangjian zhangjian  113 9月   4 2021 kafka
drwxrwxr-x.  8 zhangjian zhangjian  160 9月   4 2021 zookeeper-3.5.7
drwxr-xr-x. 11 zhangjian zhangjian  173 9月   3 2021 hadoop-3.1.3
drwxr-xr-x.  7 zhangjian zhangjian  245 4月   2 2019 jdk1.8.0_212

[zhangjian@hadoop102 module]$ ls -clt
总用量 4
drwxrwxr-x.  2 zhangjian zhangjian   76 9月  23 2021 db_log
drwxrwxr-x.  3 zhangjian zhangjian  117 9月  23 2021 applog
drwxrwxr-x. 15 zhangjian zhangjian  226 9月  20 2021 miniconda3
drwxrwxr-x.  5 zhangjian zhangjian   70 9月  20 2021 azkaban
drwxr-xr-x. 15 zhangjian zhangjian  235 9月  10 2021 spark
drwxrwxr-x.  9 zhangjian zhangjian  153 9月   6 2021 hive
drwxr-xr-x.  9 zhangjian zhangjian 4096 9月   5 2021 sqoop
drwxrwxr-x.  7 zhangjian zhangjian  232 9月   4 2021 flume
drwxr-xr-x.  8 zhangjian zhangjian  113 9月   4 2021 kafka
drwxrwxr-x.  8 zhangjian zhangjian  160 9月   4 2021 zookeeper-3.5.7
drwxr-xr-x. 11 zhangjian zhangjian  173 9月   3 2021 hadoop-3.1.3
drwxr-xr-x.  7 zhangjian zhangjian  245 9月   3 2021 jdk1.8.0_212


----注意 使用多个参数时 参数位置不正确可能会失效 (ls -fl正确) (ls -lf失效)
[zhangjian@hadoop102 hive]$ ls -lf
.  ..  conf  hcatalog  LICENSE  NOTICE  RELEASE_NOTES.txt  examples  bin  scripts  lib  jdbc
[zhangjian@hadoop102 hive]$ ls -fl
总用量 52
drwxrwxr-x.  9 zhangjian zhangjian   153 9月   6 2021 .
drwxr-xr-x. 14 zhangjian zhangjian   194 9月  20 2021 ..
drwxrwxr-x.  2 zhangjian zhangjian  4096 9月  18 2021 conf
drwxrwxr-x.  7 zhangjian zhangjian    68 9月   6 2021 hcatalog
-rwxr-xr-x.  1 zhangjian zhangjian 20798 8月  23 2019 LICENSE
-rwxr-xr-x.  1 zhangjian zhangjian   230 8月  23 2019 NOTICE
-rwxr-xr-x.  1 zhangjian zhangjian  2469 8月  23 2019 RELEASE_NOTES.txt
drwxrwxr-x.  4 zhangjian zhangjian    34 9月   6 2021 examples
drwxrwxr-x.  3 zhangjian zhangjian   157 9月   6 2021 bin
drwxrwxr-x.  4 zhangjian zhangjian    35 9月   6 2021 scripts
drwxrwxr-x.  4 zhangjian zhangjian 12288 9月   6 2021 lib
drwxrwxr-x.  2 zhangjian zhangjian    44 9月   6 2021 jdbc

--关于 ls -R 命令的测试 在子目录很少的时候特别好用，文件层次分明
[zhangjian@hadoop102 study]$ pwd
/home/zhangjian/study
[zhangjian@hadoop102 study]$ ls -R
.:
beijing  shanghai  shenzhen

./beijing:
chaoyang  haidian

./beijing/chaoyang:

./beijing/haidian:

./shanghai:
pudong

./shanghai/pudong:

./shenzhen:
nanshan

./shenzhen/nanshan:
shekou  xili

./shenzhen/nanshan/shekou:

./shenzhen/nanshan/xili:


<-->5.ll 列出目录的详细内容 每行一个目录或文件

1） 显示说明
每行列出的信息依次是： 
文件类型与权限 链接数 文件属主 文件属组 文件大小(用byte来表示) 建立或最近修改的时间(月 日 年三个字段) 目录或者文件名称

2）使用案例

[zhangjian@hadoop102 hive]$ ll
总用量 52
drwxrwxr-x. 3 zhangjian zhangjian   157 9月   6 2021 bin
drwxrwxr-x. 2 zhangjian zhangjian  4096 9月  18 2021 conf
drwxrwxr-x. 4 zhangjian zhangjian    34 9月   6 2021 examples
drwxrwxr-x. 7 zhangjian zhangjian    68 9月   6 2021 hcatalog
drwxrwxr-x. 2 zhangjian zhangjian    44 9月   6 2021 jdbc
drwxrwxr-x. 4 zhangjian zhangjian 12288 9月   6 2021 lib
-rwxr-xr-x. 1 zhangjian zhangjian 20798 8月  23 2019 LICENSE
-rwxr-xr-x. 1 zhangjian zhangjian   230 8月  23 2019 NOTICE
-rwxr-xr-x. 1 zhangjian zhangjian  2469 8月  23 2019 RELEASE_NOTES.txt
drwxrwxr-x. 4 zhangjian zhangjian    35 9月   6 2021 scripts


[zhangjian@hadoop102 module]$ ll /opt/module/hadoop-3.1.3/
总用量 180
drwxr-xr-x. 2 zhangjian zhangjian    183 9月  12 2019 bin
drwxrwxr-x. 4 zhangjian zhangjian     37 9月   3 2021 data
drwxr-xr-x. 3 zhangjian zhangjian     20 9月  12 2019 etc
drwxr-xr-x. 2 zhangjian zhangjian    106 9月  12 2019 include
drwxr-xr-x. 3 zhangjian zhangjian     20 9月  12 2019 lib
drwxr-xr-x. 4 zhangjian zhangjian    288 9月  12 2019 libexec
-rw-rw-r--. 1 zhangjian zhangjian 147145 9月   4 2019 LICENSE.txt
drwxrwxr-x. 3 zhangjian zhangjian   4096 6月  22 08:23 logs
-rw-rw-r--. 1 zhangjian zhangjian  21867 9月   4 2019 NOTICE.txt
-rw-rw-r--. 1 zhangjian zhangjian   1366 9月   4 2019 README.txt
drwxr-xr-x. 3 zhangjian zhangjian   4096 9月  12 2019 sbin

--注意 如果输入了没有的参数 则不会报错
[zhangjian@hadoop102 module]$ ll -k
总用量 4
drwxrwxr-x.  3 zhangjian zhangjian  117 9月  23 2021 applog
drwxrwxr-x.  5 zhangjian zhangjian   70 9月  20 2021 azkaban
drwxrwxr-x.  2 zhangjian zhangjian   76 9月  23 2021 db_log
drwxrwxr-x.  7 zhangjian zhangjian  232 9月   4 2021 flume
drwxr-xr-x. 11 zhangjian zhangjian  173 9月   3 2021 hadoop-3.1.3
drwxrwxr-x.  9 zhangjian zhangjian  153 9月   6 2021 hive
drwxr-xr-x.  7 zhangjian zhangjian  245 4月   2 2019 jdk1.8.0_212
drwxr-xr-x.  8 zhangjian zhangjian  113 9月   4 2021 kafka
drwxrwxr-x. 15 zhangjian zhangjian  226 9月  20 2021 miniconda3
drwxr-xr-x. 15 zhangjian zhangjian  235 9月  10 2021 spark
drwxr-xr-x.  9 zhangjian zhangjian 4096 9月   5 2021 sqoop
drwxrwxr-x.  8 zhangjian zhangjian  160 9月   4 2021 zookeeper-3.5.7
[zhangjian@hadoop102 module]$ ll
总用量 4
drwxrwxr-x.  3 zhangjian zhangjian  117 9月  23 2021 applog
drwxrwxr-x.  5 zhangjian zhangjian   70 9月  20 2021 azkaban
drwxrwxr-x.  2 zhangjian zhangjian   76 9月  23 2021 db_log
drwxrwxr-x.  7 zhangjian zhangjian  232 9月   4 2021 flume
drwxr-xr-x. 11 zhangjian zhangjian  173 9月   3 2021 hadoop-3.1.3
drwxrwxr-x.  9 zhangjian zhangjian  153 9月   6 2021 hive
drwxr-xr-x.  7 zhangjian zhangjian  245 4月   2 2019 jdk1.8.0_212
drwxr-xr-x.  8 zhangjian zhangjian  113 9月   4 2021 kafka
drwxrwxr-x. 15 zhangjian zhangjian  226 9月  20 2021 miniconda3
drwxr-xr-x. 15 zhangjian zhangjian  235 9月  10 2021 spark
drwxr-xr-x.  9 zhangjian zhangjian 4096 9月   5 2021 sqoop
drwxrwxr-x.  8 zhangjian zhangjian  160 9月   4 2021 zookeeper-3.5.7

--查看隐藏文件 ll -a

--查看文件按照时间降序排列 最新修改默认在最上面  ll -t

--查看文件 其中文件大小用b,kb,Mb,Gb单位显示   ll -h

<-->6.cd 切换目录

1）基本语法
cd [参数]

2）参数说明
参数 功能
cd 绝对路径 切换路径
cd 相对路径 切换路径
cd ~或者 cd 回到自己的家目录
cd - 回到上一次所在目录
cd .. 回到当前目录的上一级目录
cd / 跳转到根目录
cd -P 跳转到实际物理路径，而非快捷方式路径

3）使用案例

--跳转到上两级目录
[zhangjian@hadoop102 hive]$ cd ../..
[zhangjian@hadoop102 opt]$ 
[zhangjian@hadoop102 opt]$ ll
总用量 0
drwxr-xr-x. 14 zhangjian zhangjian 194 9月  20 2021 module
drwxr-xr-x. 13 zhangjian zhangjian 157 9月  20 2021 software

--返回上一次所在目录
[zhangjian@hadoop102 opt]$ cd -
/opt/module/hive
[zhangjian@hadoop102 hive]$ ls
bin  conf  examples  hcatalog  jdbc  lib  LICENSE  NOTICE  RELEASE_NOTES.txt  scripts
[zhangjian@hadoop102 hive]$ 

--路径最后一级目录后有没有/无影响，用tab键自动补全时会自带
[zhangjian@hadoop102 beijing]$ cd /opt/module/
[zhangjian@hadoop102 module]$ pwd
/opt/module
[zhangjian@hadoop102 module]$ cd /home/zhangjian/study/beijing
[zhangjian@hadoop102 beijing]$ pwd
/home/zhangjian/study/beijing


<-->7.mkdir 创建一个新的目录

1）基本语法
mkdir [选项] 要创建的目录

2）选项说明
选项 功能
-p 创建多层目录

3）使用案例

[zhangjian@hadoop102 study]$ ll
总用量 0
[zhangjian@hadoop102 study]$ mkdir shenzhen
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:46 shenzhen

--没有第一级目录直接创建第二级目录时会报错
[zhangjian@hadoop102 study]$ mkdir shanghai/pudong
mkdir: 无法创建目录"shanghai/pudong": 没有那个文件或目录

--有第一级目录直接创建第二级目录时不会报错
[zhangjian@hadoop102 study]$ mkdir shanghai
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:51 shanghai
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:46 shenzhen
[zhangjian@hadoop102 study]$ mkdir shanghai/pudong
[zhangjian@hadoop102 study]$ cd shanghai/
[zhangjian@hadoop102 shanghai]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:51 pudong

--已经有文件再创建会报错
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 3 zhangjian zhangjian 20 6月  23 12:51 shanghai
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 12:46 shenzhen
[zhangjian@hadoop102 study]$ mkdir beijing
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 12:53 beijing
drwxrwxr-x. 3 zhangjian zhangjian 20 6月  23 12:51 shanghai
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 12:46 shenzhen
[zhangjian@hadoop102 study]$ mkdir beijing
mkdir: 无法创建目录"beijing": 文件已存在

--可以在任意路径下创建其他路径下的文件夹
[zhangjian@hadoop102 beijing]$ ls
haidian
[zhangjian@hadoop102 beijing]$ cd /opt/module/
[zhangjian@hadoop102 module]$ pwd
/opt/module
[zhangjian@hadoop102 module]$ mkdir /home/zhangjian/study/beijing/chaoyang
[zhangjian@hadoop102 module]$ cd /home/zhangjian/study/beijing
[zhangjian@hadoop102 beijing]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:59 chaoyang
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 12:57 haidian

--使用-p参数
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 4 zhangjian zhangjian 37 6月  23 12:59 beijing
drwxrwxr-x. 3 zhangjian zhangjian 20 6月  23 12:51 shanghai
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 13:06 shenzhen
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 0
drwxrwxr-x. 3 zhangjian zhangjian 20 6月  23 13:06 nanshan
[zhangjian@hadoop102 shenzhen]$ cd nanshan/
[zhangjian@hadoop102 nanshan]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 13:06 shekou
[zhangjian@hadoop102 nanshan]$ cd shekou/
[zhangjian@hadoop102 shekou]$ ll
总用量 0
[zhangjian@hadoop102 shekou]$ mkdir -p /home/zhangjian/study/shenzhen/nanshan/xili
[zhangjian@hadoop102 shekou]$ cd /home/zhangjian/study/shenzhen/nanshan/
[zhangjian@hadoop102 nanshan]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 13:06 shekou
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 13:09 xili

--同时创造多个目录的语法 多个目录空格隔开就好，同时支持绝对路径和相对路径
[zhangjian@hadoop102 study]$ mkdir -p shenzhen/futian shenzhen/huohu beijing/daxing /home/zhangjian/study/shanghai/hongkou/home/zhangjian/study/shanghai/qingpu /home/zhangjian/study/shanghai/mingxing /home/zhangjian/study/beijing/xengtai beijing/miyun

--同时创造多个目录的语法和命令行中的换行问题
--多个目录中可以包含同时不存在的路径，已经存在也不会报错
--使用\+enter 这里直接接在输入字符后面或者空格再输入\+enter都可以
[zhangjian@hadoop102 study]$ mkdir -p shenzhen/baoan shenzhen/guangming \
> /home/zhangjian/study/shenzhen/longhua/beizhan shenzhen/longhua/guanlan\
> shenzhen/yantian/haishan/haha shenzhen/yantian/haha

--已经存在的目录，不会重新创建，多次创建同一个目录也不会报错
[zhangjian@hadoop102 yantian]$ pwd
/home/zhangjian/study/shenzhen/yantian
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian/haha
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian/haha shenzhen/yantian/haha shenzhen/yantian/haha/
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 13:40 shenzhen
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian/haha
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 13:40 shenzhen
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian/haha
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 13:40 shenzhen

<-->8.rmdir 删除一个空的目录

1）基本语法
rmdir 要删除的空目录

删除多个的语法和创建一样

3）使用案例

[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 13:40 shenzhen

[zhangjian@hadoop102 yantian]$ rmidr haha/ shenzhen/
bash: rmidr: 未找到命令...
相似命令是： 'rmdir'
-- 这里发现输出错误的命令rmidr时都可以在输入路径时自动补全

[zhangjian@hadoop102 yantian]$ rmdir haha/ shenzhen/
rmdir: 删除 "shenzhen/" 失败: 目录非空
--不是空目录不能删除

[zhangjian@hadoop102 yantian]$ rmdir haha/ shenzhen/yantian/haha/
rmdir: 删除 "haha/" 失败: 没有那个文件或目录
--没有目录时会报错

[zhangjian@hadoop102 yantian]$ rmdir shenzhen/yantian/haha
rmdir: 删除 "shenzhen/yantian/haha" 失败: 没有那个文件或目录

[zhangjian@hadoop102 yantian]$ rmdir shenzhen/yantian/ shenzhen/
[zhangjian@hadoop102 yantian]$ ll
--不能递归删除 但是可以同时删除有关联的目录，

总用量 0

--多级目录同时删除测试

--首先创建多级空目录并查看确认
zhangjian@hadoop102 yantian]$ ll
总用量 0
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian shenzhen/ shenzhen/yantian/haha haha
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 14:03 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 14:03 shenzhen
[zhangjian@hadoop102 yantian]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 0
drwxrwxr-x. 3 zhangjian zhangjian 18 6月  23 14:03 yantian
[zhangjian@hadoop102 shenzhen]$ cd yantian/
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 14:03 haha
[zhangjian@hadoop102 yantian]$ cd ../../..
[zhangjian@hadoop102 shenzhen]$ cd yantian/
[zhangjian@hadoop102 yantian]$ pwd
/home/zhangjian/study/shenzhen/yantian
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 14:03 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 14:03 shenzhen

[zhangjian@hadoop102 yantian]$ rmdir shenzhen/ shenzhen/yantian/ shenzhen/yantian/haha/
rmdir: 删除 "shenzhen/" 失败: 目录非空
rmdir: 删除 "shenzhen/yantian/" 失败: 目录非空
--从父目录到子目录删除报错

[zhangjian@hadoop102 yantian]$ mkdir shenzhen/yantian/haha
--刚才最内层的目录已被删除，需要重新创建

[zhangjian@hadoop102 yantian]$  rmdir shenzhen/yantian/haha/ shenzhen/yantian/ shenzhen/
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 14:03 haha
--从子目录到父目录依次删除时不会报错，且(qie)正确删除，说明命令执行时是从前到后依次执行

--rmdir递归删除测试 说明其不支持递归删除
[zhangjian@hadoop102 yantian]$ ll
总用量 0
[zhangjian@hadoop102 yantian]$ mkdir -p shenzhen/yantian shenzhen/ shenzhen/yantian/haha haha
[zhangjian@hadoop102 yantian]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 14:15 haha
drwxrwxr-x. 3 zhangjian zhangjian 21 6月  23 14:15 shenzhen
[zhangjian@hadoop102 yantian]$ rmdir -p haha/ shenzhen/
rmdir: 删除 "shenzhen/" 失败: 目录非空


<-->9.touch 创建空文件

1）基本语法
touch 文件名称

3）使用案例

--同时创建多个目录，且无论什么文件类型都可以创建
[zhangjian@hadoop102 study]$ touch zs.txt wz tx.zip
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 108 6月  23 13:35 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 zs.txt

--绝对路径和相对路径都可以 这说明所有在可以输入路径的参数的位置只要输入正确的路径就可以
[zhangjian@hadoop102 study]$ touch sl.exe lji.jar shenzhen/kkk.ini /home/zhangjian/study/shenzhen/ccc
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 134 6月  23 16:50 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian   7 6月  23 16:45 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian

--如果文件已经存在，则修改时间会更新但是文件内容不会改变
[zhangjian@hadoop102 study]$ touch zs.txt
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 108 6月  23 13:35 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ vim zs.txt 
[zhangjian@hadoop102 study]$ head zs.txt
ll
ddd
[zhangjian@hadoop102 study]$ touch zs.txt 
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 108 6月  23 13:35 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian   7 6月  23 16:45 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ vim zs.txt 
[zhangjian@hadoop102 study]$ head zs.txt 
ll
ddd

--如果文件前有未存在的目录则会创建失败
[zhangjian@hadoop102 chengdu]$ touch xiongmao /wuhou/jingli
touch: 无法创建"/wuhou/jingli": 没有那个文件或目录


<-->10.cp 复制文件或目录

1）基本语法
cp [选项] 源文件(source) 目标文件(dest)

2）选项说明

选项 功能
-r 递归复制整个文件夹

3）经验技巧 
a.强制覆盖不提示的方法：\cp   --实际测试并没有什么区别
b.复制多个文件或目录 最后一个目录是目标文件
	语法1 cp -r source1 source2 source3 ... dest
	语法2 cp source1 source2 source3 ... dest
	
-----a 测试开始-------------------
--使用\cp
[zhangjian@hadoop102 shenzhen]$ head lsaf 

dafd

dafsfdfd
[zhangjian@hadoop102 shenzhen]$ cd beijing/
[zhangjian@hadoop102 beijing]$ ll
总用量 4
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:14 chaoyang
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:14 daxing
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:14 haidian
-rw-rw-r--. 1 zhangjian zhangjian 16 6月  23 17:16 lsaf
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:14 miyun
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:14 xengtai
[zhangjian@hadoop102 beijing]$ vim lsaf 
[zhangjian@hadoop102 beijing]$ head lsaf 

dafd
sfasdfdasfasdfsdasd
[zhangjian@hadoop102 beijing]$ \cp lsaf ../lsaf
[zhangjian@hadoop102 beijing]$ head ../lsaf 

dafd

--使用cp
[zhangjian@hadoop102 beijing]$ head ../lsaf 

dafd
sfasdfdasfasdfsdasd
[zhangjian@hadoop102 beijing]$ vim lsaf 
[zhangjian@hadoop102 beijing]$ head lsaf 
i1111111
222222222222
[zhangjian@hadoop102 beijing]$ cp lsaf ../lsaf 
[zhangjian@hadoop102 beijing]$ head ../lsaf 
i1111111
222222222222
[zhangjian@hadoop102 beijing]$ 
-----a 测试结束-------------------

-----b 测试开始-------------------

--递归复制的正确方法
[zhangjian@hadoop102 study]$ cp -r 111 222 555 shenzhen/
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:39 111
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:39 222
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:39 555
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  7 zhangjian zhangjian  91 6月  23 17:25 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 ccc
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 kkk.ini
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
-rw-rw-r--.  1 zhangjian zhangjian  22 6月  23 17:25 lsaf
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 wz
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:06 zs.txt

--非递归复制多个文件 时间刷新过说明复制成功
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:39 111
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:39 222
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:39 555
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  7 zhangjian zhangjian  91 6月  23 17:25 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 ccc
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 kkk.ini
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
-rw-rw-r--.  1 zhangjian zhangjian  22 6月  23 17:25 lsaf
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 wz
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:06 zs.txt
[zhangjian@hadoop102 shenzhen]$ cd ..
[zhangjian@hadoop102 study]$ cp 111 222 shenzhen/
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:42 111
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:42 222
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:39 555
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  7 zhangjian zhangjian  91 6月  23 17:25 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 ccc
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 kkk.ini
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
-rw-rw-r--.  1 zhangjian zhangjian  22 6月  23 17:25 lsaf
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 wz
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:06 zs.txt


--报错的情况 这里不是使用递归的语法 cp: 略过目录"shenzhen/"
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x.  7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 175 6月  23 17:17 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ cp sl.exe shenzhen/ wz shenzhen/
cp: 略过目录"shenzhen/"
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
drwxrwxr-x. 7 zhangjian zhangjian 91 6月  23 17:25 beijing
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
-rw-rw-r--. 1 zhangjian zhangjian 22 6月  23 17:25 lsaf
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:29 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:29 wz
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian
-rw-rw-r--. 1 zhangjian zhangjian 11 6月  23 17:06 zs.txt

--递归操作 虽然报错 但是依然可以自己复制自己
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
drwxrwxr-x. 7 zhangjian zhangjian 91 6月  23 17:25 beijing
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
-rw-rw-r--. 1 zhangjian zhangjian 22 6月  23 17:25 lsaf
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:29 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:29 wz
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian
-rw-rw-r--. 1 zhangjian zhangjian 11 6月  23 17:06 zs.txt
[zhangjian@hadoop102 shenzhen]$ cd ..
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x.  7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 199 6月  23 17:29 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ cp -r tx.zip shenzhen/ shanghai/ shenzhen/
cp: 无法将目录"shenzhen/" 复制到自己"shenzhen/shenzhen"
[zhangjian@hadoop102 shenzhen]$ pwd
/home/zhangjian/study/shenzhen/shenzhen
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:34 baoan
drwxrwxr-x. 7 zhangjian zhangjian 91 6月  23 17:34 beijing
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:34 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:34 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:34 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:34 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:34 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 17:34 longhua
-rw-rw-r--. 1 zhangjian zhangjian 22 6月  23 17:34 lsaf
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 17:34 nanshan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:34 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:34 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 17:34 wz
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 17:34 yantian
-rw-rw-r--. 1 zhangjian zhangjian 11 6月  23 17:34 zs.txt

-----b 测试结束-------------------

4）使用案例

--如果两个文件一样只是路径不同，会强制覆盖原来的文件不提示
[zhangjian@hadoop102 study]$ head zs.txt 
ll
ddd
[zhangjian@hadoop102 shenzhen]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian
[zhangjian@hadoop102 shenzhen]$ touch zs.txt
[zhangjian@hadoop102 shenzhen]$ vim zs.txt 
[zhangjian@hadoop102 shenzhen]$ head zs.txt 
s;;;
dsfaf
[zhangjian@hadoop102 shenzhen]$ cp zs.txt ../zs.txt 
[zhangjian@hadoop102 shenzhen]$ cd ..
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 148 6月  23 17:06 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ head zs.txt 
s;;;
dsfaf

--不加参数r会报错
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 148 6月  23 17:06 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ cp beijing/ shenzhen/
cp: 略过目录"beijing/"
[zhangjian@hadoop102 study]$ ll
总用量 4
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 148 6月  23 17:06 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--. 1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ cd shenzhen/
[zhangjian@hadoop102 shenzhen]$ ll
总用量 4
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian
-rw-rw-r--. 1 zhangjian zhangjian 11 6月  23 17:06 zs.txt

--如果不存在目标文件，则会创建
[zhangjian@hadoop102 beijing]$ ll
总用量 0
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 17:14 chaoyang
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 17:14 daxing
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 17:14 haidian
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 17:14 miyun
drwxrwxr-x. 2 zhangjian zhangjian 6 6月  23 17:14 xengtai
[zhangjian@hadoop102 beijing]$ pwd
/home/zhangjian/study/shenzhen/beijing
[zhangjian@hadoop102 beijing]$ touch lsaf
[zhangjian@hadoop102 beijing]$ vim lsaf 
[zhangjian@hadoop102 beijing]$ cp lsaf ../lsaf
[zhangjian@hadoop102 beijing]$ cd ..
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 baoan
drwxrwxr-x. 7 zhangjian zhangjian 91 6月  23 17:16 beijing
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 ccc
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 futian
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:35 guangming
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 13:22 huohu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 16:50 kkk.ini
drwxrwxr-x. 4 zhangjian zhangjian 44 6月  23 13:35 longhua
-rw-rw-r--. 1 zhangjian zhangjian 16 6月  23 17:17 lsaf
drwxrwxr-x. 4 zhangjian zhangjian 32 6月  23 13:09 nanshan
drwxrwxr-x. 2 zhangjian zhangjian  6 6月  23 16:41 yantian
-rw-rw-r--. 1 zhangjian zhangjian 11 6月  23 17:06 zs.txt
[zhangjian@hadoop102 shenzhen]$ head lsaf 

dafd

dafsfdfd


<-->11.rm 删除文件或目录

1）基本语法
rm [选项] deleteFile （功能描述：递归删除目录中所有内容）

2）选项说明

选项 功能
-r 递归删除目录中所有内容
-f 强制执行删除操作，而不提示用于进行确认。-v 显示指令的详细执行过程
-v 显示指令的详细执行过程

3）使用案例

--这里不使用f也不会提示
[zhangjian@hadoop102 study]$ ll
总用量 4
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:37 111
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:37 222
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:37 333.txt
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 17:38 444
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:38 555
drwxrwxr-x.  7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 13 zhangjian zhangjian 278 6月  23 17:39 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx
[zhangjian@hadoop102 study]$ rm -r 111 222 
[zhangjian@hadoop102 study]$ ll
总用量 4
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:37 333.txt
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 17:38 444
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:38 555
drwxrwxr-x.  7 zhangjian zhangjian  79 6月  23 13:22 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 lji.jar
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 13 zhangjian zhangjian 278 6月  23 17:39 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:42 wz
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:07 zs.txt
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:43 zs.xtx

-- 参数 -rv 的测试
[zhangjian@hadoop102 shenzhen]$ ll
总用量 8
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:42 111
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:42 222
drwxrwxr-x.  3 zhangjian zhangjian  18 6月  23 17:39 555
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  7 zhangjian zhangjian  91 6月  23 17:25 beijing
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 ccc
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 16:50 kkk.ini
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
-rw-rw-r--.  1 zhangjian zhangjian  22 6月  23 17:25 lsaf
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 wz
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:06 zs.txt
[zhangjian@hadoop102 shenzhen]$ rm -rv 111 222 beijing/
已删除"111"
已删除"222"
已删除目录："beijing/haidian"
已删除目录："beijing/chaoyang"
已删除目录："beijing/daxing"
已删除目录："beijing/xengtai"
已删除目录："beijing/miyun"
已删除"beijing/lsaf"
已删除目录："beijing/"

--同一个文件被删除两次 则会报错但是目标已经删除
[zhangjian@hadoop102 shenzhen]$ ll
总用量 4
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 sl.exe
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:29 wz
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian
-rw-rw-r--.  1 zhangjian zhangjian  11 6月  23 17:06 zs.txt
[zhangjian@hadoop102 shenzhen]$ rm -r sl.exe sl.exe wz zs.txt 
rm: 无法删除"sl.exe": 没有那个文件或目录
[zhangjian@hadoop102 shenzhen]$ ll
总用量 0
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 baoan
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 futian
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:35 guangming
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 13:22 huohu
drwxrwxr-x.  4 zhangjian zhangjian  44 6月  23 13:35 longhua
drwxrwxr-x.  4 zhangjian zhangjian  32 6月  23 13:09 nanshan
drwxrwxr-x.  5 zhangjian zhangjian  51 6月  23 17:34 shanghai
drwxrwxr-x. 10 zhangjian zhangjian 213 6月  23 17:34 shenzhen
-rw-rw-r--.  1 zhangjian zhangjian   0 6月  23 17:34 tx.zip
drwxrwxr-x.  2 zhangjian zhangjian   6 6月  23 16:41 yantian


<-->12.mv 移动文件与目录或重命名

1）基本语法
（1）mv oldNameFile newNameFile （功能描述：重命名）
（2）mv /temp/movefile /targetFolder （功能描述：移动文件）

-------注意---------重命名只能时两个元素，有大于两个元素时，最后一个必须是存在的文件且是移动操作
--注意 为什么移动和重命名这两个命令都是mv
--他们的共性在于执行命令后前面的旧文件或者文件夹都不见了

--对于两个元素而已
--如果后面路径下的文件或者目录不存在则视为移动
--如果后面路径下的文件或者目录存在则视为重命名
-------注意---------

2）案例实操

--两个元素时，第二个目录不存在会报错
[zhangjian@hadoop102 study]$ mv idea /dalian
mv: 无法将"idea" 移动至"/dalian": 权限不够

--都是文件时第二个不存在则为重命名
[zhangjian@hadoop102 study]$ mv idea idea_dalian
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian  33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:31 tianjing

--两个都是文件时，第二个不存在则会重命名文件
[zhangjian@hadoop102 study]$ mv tianjing/ dalian/
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:31 dalian
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian  33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark

--两个元素时，第一个为目录，最后一个元素是非目录时会报错
[zhangjian@hadoop102 study]$ mv tianjing/ idea
mv: 无法以目录"tianjing/" 来覆盖非目录"idea"

--两个元素，且都是存在的文件，则会删除第一个元素，第二个元素不动。
[zhangjian@hadoop102 study]$ mv python flink
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian  33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:31 tianjing

--多个文件移动到一个文件夹中
[zhangjian@hadoop102 hangzhou]$ ll
总用量 0
-rw-rw-r--. 1 zhangjian zhangjian 0 6月  23 22:23 idea
-rw-rw-r--. 1 zhangjian zhangjian 0 6月  23 22:23 java
-rw-rw-r--. 1 zhangjian zhangjian 0 6月  23 22:23 python
-rw-rw-r--. 1 zhangjian zhangjian 0 6月  23 22:23 spark
[zhangjian@hadoop102 hangzhou]$ mv java idea python spark ../
[zhangjian@hadoop102 hangzhou]$ cd ..
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:29 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 java
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 python
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark

--文件和文件夹移动到目录中 有多个元素时，最后一个如果是已经存在的目录则把之前的元素移动到最后一个元素中
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 3 zhangjian zhangjian  49 6月  23 22:36 chengdu
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:29 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 java
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 python
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:31 tianjing
[zhangjian@hadoop102 study]$ mv java chengdu/ hangzhou/
[zhangjian@hadoop102 study]$ cd hangzhou/
[zhangjian@hadoop102 hangzhou]$ ll
总用量 0
drwxrwxr-x. 3 zhangjian zhangjian 49 6月  23 22:36 chengdu
-rw-rw-r--. 1 zhangjian zhangjian  0 6月  23 22:23 java
[zhangjian@hadoop102 hangzhou]$ ls -R
.:
chengdu  java

./chengdu:
jingli  wuhou  xiongmao

./chengdu/wuhou:

--多个元素测试 四个元素时还是报错 不能同时修改两个文件的名称
[zhangjian@hadoop102 hangzhou]$ mv java javascirp spark pyspark
mv: 目标"pyspark" 不是目录

--大于两个元素时，最后一个元素一定要是存在的目录，才能把之前的元素都移动到最后一个文件中
[zhangjian@hadoop102 study]$ mv idea python dalian
mv: 目标"dalian" 不是目录
[zhangjian@hadoop102 study]$ ll
总用量 0
drwxrwxr-x. 7 zhangjian zhangjian  79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 chongqing
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:31 dalian
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 eclipse
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian   6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian  33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian  51 6月  23 13:22 shanghai
drwxrwxr-x. 9 zhangjian zhangjian 109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian   0 6月  23 22:23 spark
[zhangjian@hadoop102 study]$ mv flink spark zhengzhou/
mv: 目标"zhengzhou/" 不是目录
[zhangjian@hadoop102 study]$ mv flink spark /zhengzhou
mv: 目标"/zhengzhou" 不是目录


<-->13.cat 查看文件内容

查看文件内容，从第一行开始显示

1）基本语法
cat [选项] 要查看的文件

2）选项说明
选项 功能描述
-n 显示所有行的行号，包括空行

3）经验技巧
一般查看比较小的文件，一屏幕能显示全的

<-->14.more 文件内容分屏查看器

more 指令是一个基于 VI 编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容。
more 指令中内置了若干快捷键，详见操作说明。

1）基本语法
more 要查看的文件

2）操作说明

操作 功能说明

空白键 (space) 代表向下翻一页；
Enter 代表向下翻『一行』；
q 代表立刻离开 more ，不再显示该文件内容。
Ctrl+F 向下滚动一屏
Ctrl+B 返回上一屏
= 输出当前行的行号
:f 输出文件名和当前行的行号


<-->15.less 分屏显示文件内容

less 指令用来分屏查看文件内容，它的功能与 more 指令类似，但是比more 指令更加强大，支持各种显示终端。
less 指令在显示文件内容时，并不是一次将整个文件加载之后才显示，
而是根据显示需要加载内容，对于显示大型文件具有较高的效率。

1）基本语法
less 要查看的文件

2）操作说明

操作 功能说明
空白键 向下翻动一页；
[pagedown] 向下翻动一页
[pageup] 向上翻动一页；
/字串 向下搜寻『字串』的功能；n：向下查找；N：向上查找；
?字串 向上搜寻『字串』的功能；n：向上查找；N：向下查找；
q 离开 less 这个程序；

3）经验技巧
用SecureCRT时[pagedown]和[pageup]可能会出现无法识别的问题。


<-->16.echo
echo 输出内容到控制台

1）基本语法
echo [选项] [输出内容]

-e： 支持反斜线控制的字符转换
控制字符 作用
\\ 输出\本身
\n 换行符
\t 制表符，也就是Tab键

2）案例实操
[atguigu@hadoop101 ~]$ echo “hello\tworld”
hello\tworld
[atguigu@hadoop101 ~]$ echo -e “hello\tworld”
hello world


<-->17.head 显示文件头部内容

head 用于显示文件的开头部分内容，默认情况下 head 指令显示文件的前10 行内容。1）基本语法
head 文件 （功能描述：查看文件头10行内容）
head -n 5 文件 （功能描述：查看文件头5行内容，5可以是任意行数）2）选项说明

选项 功能
-n<行数> 指定显示头部内容的行数
3）案例实操
（1）查看文件的头2行
[root@hadoop101 ~]# head -n 2 smartd.conf


<-->18.tail 输出文件尾部内容
tail用于输出文件中尾部的内容，默认情况下 tail指令显示文件的后10 行内容。

1） 基本语法
（1）tail 文件 （功能描述：查看文件尾部10行内容）
（2）tail -n 5 文件 （功能描述：查看文件尾部5行内容，5可以是任意行数）
（3）tail -f 文件 （功能描述：实时追踪该文档的所有更新）2） 选项说明

选项 功能
-n<行数> 输出文件尾部 n 行内容
-f 显示文件最新追加的内容，监视文件变化

3）案例实操
（1）查看文件尾 1 行内容
[root@hadoop101 ~]# tail -n 1 smartd.conf
（2）实时追踪该档的所有更新
[root@hadoop101 ~]# tail -f houge.txt


<-->19.> >>
 >  输出重定向(覆盖)
 >> 追加
 
1）基本语法
（1）ls -l > 文件 （功能描述：列表的内容写入文件 a.txt 中（覆盖写））
（2）ls -al >> 文件 （功能描述：列表的内容追加到文件aa.txt 的末尾）
（3）cat 文件 1 > 文件 2 （功能描述：将文件 1 的内容覆盖到文件2）
（4）echo “内容” >> 文件

2）案例实操
（1）将 ls 查看信息写入到文件中
[root@hadoop101 ~]# ls -l>houge.txt
（2）将 ls 查看信息追加到文件中
[root@hadoop101 ~]# ls -l>>houge.txt
（3）采用 echo 将 hello 单词追加到文件中
[root@hadoop101 ~]# echo hello>>houge.txt


<-->20.ln 软链接
软链接也称为符号链接，类似于 windows 里的快捷方式，有自己的数据块，主要存放了链接其他文件的路径。

1）基本语法
ln -s [原文件或目录] [软链接名] （功能描述：给原文件创建一个软链接）

2）经验技巧
删除软链接： rm -rf 软链接名，而不是 rm -rf 软链接名/
如果使用 rm -rf 软链接名/ 删除，会把软链接对应的真实目录下内容删掉查询：
通过 ll 就可以查看，列表属性第 1 位是 l，尾部会有位置指向。

3）案例实操
（1）创建软连接
[root@hadoop101 ~]# mv houge.txt xiyou/dssz/
[root@hadoop101 ~]# ln -s xiyou/dssz/houge.txt ./houzi
[root@hadoop101 ~]# ll
lrwxrwxrwx. 1 root root 20 6 月 17 12:56 houzi -> xiyou/dssz/houge.txt
（2）删除软连接(注意不要写最后的/)
[root@hadoop101 ~]# rm -rf houzi
（3）进入软连接实际物理路径
[root@hadoop101 ~]# ln -s xiyou/dssz/ ./dssz
[root@hadoop101 ~]# cd -P dssz/


<-->21.history 查看已经执行过的历史命令
1）基本语法
history （功能描述：查看已经执行过历史命令）
2）案例实操
（1）查看已经执行过的历史命令
[root@hadoop101 test1]# history


--------------------------- <-->02.时间日期类命令-----------------------------------

<-->22.date 时间日期

1）基本语法
date [OPTION]... [+FORMAT]

2）选项说明

选项 功能
-d<时间字符串> 显示指定的“时间字符串”表示的时间，而非当前时间-s<日期时间> 设置系统日期时间

3）参数说明

参数 功能
<+日期时间格式> 指定显示时使用的日期时间格式

a.用法一 显示当前时间
date 显示当前时间
1）基本语法
（1）date （功能描述：显示当前时间）
（2）date +%Y （功能描述：显示当前年份）
（3）date +%m （功能描述：显示当前月份）
（4）date +%d （功能描述：显示当前是哪一天）
（5）date "+%Y-%m-%d %H:%M:%S" （功能描述：显示年月日时分秒）2）案例实操

（1）显示当前时间信息
[root@hadoop101 ~]# date
2017 年 06 月 19 日 星期一 20:53:30 CST
（2）显示当前时间年月日
[root@hadoop101 ~]# date +%Y%m%d
20170619
（3）显示当前时间年月日时分秒 --这里加引号是因为日期和时间中间有空格，不然会报错
[root@hadoop101 ~]# date "+%Y-%m-%d %H:%M:%S"
2017-06-19 20:54:58
[zhangjian@hadoop102 futian]$ date '+%Y-%m-%d %H:%M:%S'
2022-06-24 02:42:44

[zhangjian@hadoop102 futian]$ date +%Y-%m-%d %H:%M:%S
date: 额外的操作数 "%H:%M:%S"
Try 'date --help' for more information.

（4）显示当前时间年月日时分秒
[zhangjian@hadoop102 futian]$ date +%Y-%m-%d/%H:%M:%S
2022-06-24/02:38:48

（5）显示指定日期的标准化格式
[zhangjian@hadoop103 ~]$ date -d "-1 day" +%F
2022-06-30



b.用法二 显示非当前时间

显示非当前时间
1）基本语法
（1）date -d 'n days ago' （功能描述：显示前n天时间）
（2）date -d '-n days ago' （功能描述：显示后n时间）

2）案例实操
[zhangjian@hadoop102 futian]$ date -d '366 days ago'
2021年 06月 23日 星期三 02:53:11 CST
[zhangjian@hadoop102 futian]$ date -d '-366 days ago'
2023年 06月 25日 星期日 02:53:26 CST
[zhangjian@hadoop102 futian]$ date -d '-366 years ago'
2388年 06月 24日 星期五 02:53:45 CST
[zhangjian@hadoop102 futian]$ date -d '400 months ago'
1989年 02月 24日 星期五 02:54:25 CST
[zhangjian@hadoop102 futian]$ date -d '200 months ago'
2005年 10月 24日 星期一 02:54:56 CST
[zhangjian@hadoop102 futian]$ date -d '200 weeks ago'
2018年 08月 24日 星期五 02:55:46 CST


c.用法三 设置系统时间

1）基本语法
date -s 字符串时间

2）案例实操
（1）设置系统当前时间
[root@hadoop101 ~]# date -s "2017-06-19 20:52:18"


<-->22.cal 查看日历

1）基本语法
cal [选项] （功能描述：不加选项，显示本月日历）

2）选项说明

选项 功能
 -j     显示儒略历的(Julian)日期 (以 1 为基的天数, 从 1 月 1 日开始计数) 
 -m     显示星期一作为一周的第一天..  (缺省为星期日.)
3）案例实操
（1）查看当前月的日历
[root@hadoop101 ~]# cal
      六月 2022     
日 一 二 三 四 五 六
          1  2  3  4
 5  6  7  8  9 10 11
12 13 14 15 16 17 18
19 20 21 22 23 24 25
26 27 28 29 30


（2）查看 1993 年的日历
[root@hadoop101 ~]# cal 1993
                               1993                               

        一月                   二月                   三月        
日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六
                1  2       1  2  3  4  5  6       1  2  3  4  5  6
 3  4  5  6  7  8  9    7  8  9 10 11 12 13    7  8  9 10 11 12 13
10 11 12 13 14 15 16   14 15 16 17 18 19 20   14 15 16 17 18 19 20
17 18 19 20 21 22 23   21 22 23 24 25 26 27   21 22 23 24 25 26 27
24 25 26 27 28 29 30   28                     28 29 30 31
31
        四月                   五月                   六月        
日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六
             1  2  3                      1          1  2  3  4  5
 4  5  6  7  8  9 10    2  3  4  5  6  7  8    6  7  8  9 10 11 12
11 12 13 14 15 16 17    9 10 11 12 13 14 15   13 14 15 16 17 18 19
18 19 20 21 22 23 24   16 17 18 19 20 21 22   20 21 22 23 24 25 26
25 26 27 28 29 30      23 24 25 26 27 28 29   27 28 29 30
                       30 31
        七月                   八月                   九月        
日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六
             1  2  3    1  2  3  4  5  6  7             1  2  3  4
 4  5  6  7  8  9 10    8  9 10 11 12 13 14    5  6  7  8  9 10 11
11 12 13 14 15 16 17   15 16 17 18 19 20 21   12 13 14 15 16 17 18
18 19 20 21 22 23 24   22 23 24 25 26 27 28   19 20 21 22 23 24 25
25 26 27 28 29 30 31   29 30 31               26 27 28 29 30

        十月                  十一月                 十二月       
日 一 二 三 四 五 六   日 一 二 三 四 五 六   日 一 二 三 四 五 六
                1  2       1  2  3  4  5  6             1  2  3  4
 3  4  5  6  7  8  9    7  8  9 10 11 12 13    5  6  7  8  9 10 11
10 11 12 13 14 15 16   14 15 16 17 18 19 20   12 13 14 15 16 17 18
17 18 19 20 21 22 23   21 22 23 24 25 26 27   19 20 21 22 23 24 25
24 25 26 27 28 29 30   28 29 30               26 27 28 29 30 31
31

（3）把星期一当做一周的第一天
[zhangjian@hadoop102 futian]$ cal -m
      六月 2022     
一 二 三 四 五 六 日
       1  2  3  4  5
 6  7  8  9 10 11 12
13 14 15 16 17 18 19
20 21 22 23 24 25 26
27 28 29 30

（4）指定月份的日历
[zhangjian@hadoop102 futian]$ cal 7 2022
      七月 2022     
日 一 二 三 四 五 六
                1  2
 3  4  5  6  7  8  9
10 11 12 13 14 15 16
17 18 19 20 21 22 23
24 25 26 27 28 29 30
31

（4）显示指定年份月份日历 每一天是这一年的第几天
[zhangjian@hadoop102 futian]$ cal -mj 7 2022
         七月 2022         
 一  二  三  四  五  六  日
                182 183 184
185 186 187 188 189 190 191
192 193 194 195 196 197 198
199 200 201 202 203 204 205
206 207 208 209 210 211 212

[zhangjian@hadoop102 futian]$ cal -mj 12 2022
        十二月 2022        
 一  二  三  四  五  六  日
            335 336 337 338
339 340 341 342 343 344 345
346 347 348 349 350 351 352
353 354 355 356 357 358 359
360 361 362 363 364 365

[zhangjian@hadoop102 futian]$ cal -mj 1 2022
         一月 2022         
 一  二  三  四  五  六  日
                      1   2
  3   4   5   6   7   8   9
 10  11  12  13  14  15  16
 17  18  19  20  21  22  23
 24  25  26  27  28  29  30
 31

 
--------------------------- <-->03.用户管理类&用户组管理类命令----------------------------

---------------------------常用重要命令-----------------------

<-->23.su 切换用户
su: swith user 切换用户

1）基本语法
su 用户名称 （功能描述：切换用户，只能获得用户的执行权限，不能获得环境变量）
su - 用户名称 （功能描述：切换到用户并获得该用户的环境变量及执行权限）

2）案例实操
（1）切换用户
[root@hadoop101 ~]#su tangseng
[root@hadoop101 ~]#echo $PATH
/usr/lib64/qt3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
[root@hadoop101 ~]#exit
[root@hadoop101 ~]#su - tangseng
[root@hadoop101 ~]#echo $PATH
/usr/lib64/qt3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/tangseng/bin


<-->24.sudo 设置普通用户具有root权限  --普通用户使用root权限的前提是在配置文件中修改过设置

1）添加 atguigu 用户，并对其设置密码。
[root@hadoop101 ~]#useradd atguigu
[root@hadoop101 ~]#passwd atguigu
2）修改配置文件
[root@hadoop101 ~]#vi /etc/sudoers 修改 /etc/sudoers 文件，找到下面一行(91 行)，
在 root 下面添加一行，如下所示：
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
atguigu ALL=(ALL) ALL
或者配置成采用 sudo 命令时，不需要输入密码
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
atguigu ALL=(ALL) NOPASSWD:ALL
修改完毕，现在可以用 atguigu 帐号登录，然后用命令 sudo ，即可获得root 权限进行操作。

3）案例实操
（1）用普通用户在/opt 目录下创建一个文件夹
[atguigu@hadoop101 opt]$ sudo mkdir module
[root@hadoop101 opt]# chown atguigu:atguigu module/

--------------------------------------------------------------

--其他用户管理命令
7.4.1 useradd 添加新用户
1）基本语法
useradd 用户名 （功能描述：添加新用户）
useradd -g 组名 用户名 （功能描述：添加新用户到某个组）
2）案例实操
（1）添加一个用户
[root@hadoop101 ~]# useradd tangseng
[root@hadoop101 ~]#ll /home/

7.4.2 passwd 设置用户密码
1）基本语法
passwd 用户名 （功能描述：设置用户密码）
2）案例实操
（1）设置用户的密码
[root@hadoop101 ~]# passwd tangseng

7.4.3 id 查看用户是否存在
1）基本语法
id 用户名
2）案例实操
（1）查看用户是否存在
[root@hadoop101 ~]#id tangseng

7.4.4 cat /etc/passwd 查看创建了哪些用户  --其实用户还挺多的
1）案例实操
[zhangjian@hadoop102 futian]$ cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
operator:x:11:0:operator:/root:/sbin/nologin
games:x:12:100:games:/usr/games:/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
nobody:x:99:99:Nobody:/:/sbin/nologin
systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
dbus:x:81:81:System message bus:/:/sbin/nologin
polkitd:x:999:998:User for polkitd:/:/sbin/nologin
sssd:x:998:996:User for sssd:/:/sbin/nologin
libstoragemgmt:x:997:994:daemon account for libstoragemgmt:/var/run/lsm:/sbin/nologin
rpc:x:32:32:Rpcbind Daemon:/var/lib/rpcbind:/sbin/nologin
colord:x:996:993:User for colord:/var/lib/colord:/sbin/nologin
gluster:x:995:992:GlusterFS daemons:/var/run/gluster:/sbin/nologin
saslauth:x:994:76:Saslauthd user:/run/saslauthd:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
setroubleshoot:x:993:990::/var/lib/setroubleshoot:/sbin/nologin
rtkit:x:172:172:RealtimeKit:/proc:/sbin/nologin
pulse:x:171:171:PulseAudio System Daemon:/var/run/pulse:/sbin/nologin
chrony:x:992:987::/var/lib/chrony:/sbin/nologin
rpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologin
nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin
unbound:x:991:986:Unbound DNS resolver:/etc/unbound:/sbin/nologin
tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin
usbmuxd:x:113:113:usbmuxd user:/:/sbin/nologin
geoclue:x:990:984:User for geoclue:/var/lib/geoclue:/sbin/nologin
radvd:x:75:75:radvd user:/:/sbin/nologin
qemu:x:107:107:qemu user:/:/sbin/nologin
ntp:x:38:38::/etc/ntp:/sbin/nologin
gdm:x:42:42::/var/lib/gdm:/sbin/nologin
gnome-initial-setup:x:989:983::/run/gnome-initial-setup/:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
avahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologin
postfix:x:89:89::/var/spool/postfix:/sbin/nologin
tcpdump:x:72:72::/:/sbin/nologin
zhangjian:x:1000:1000:zhangjian:/home/zhangjian:/bin/bash
mysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/false

7.4.6 userdel 删除用户
1）基本语法
（1）userdel 用户名 （功能描述：删除用户但保存用户主目录）
（2）userdel -r 用户名 （功能描述：用户和用户主目录，都删除）
2）选项说明
选项 功能
-r 删除用户的同时，删除与用户相关的所有文件。
3）案例实操
（1）删除用户但保存用户主目录
[root@hadoop101 ~]#userdel tangseng
[root@hadoop101 ~]#ll /home/
（2）删除用户和用户主目录，都删除
[root@hadoop101 ~]#useradd zhubajie
[root@hadoop101 ~]#ll /home/
[root@hadoop101 ~]#userdel -r zhubajie
[root@hadoop101 ~]#ll /home/

7.4.7 who 查看登录用户信息
1）基本语法
（1）whoami （功能描述：显示自身用户名称）
（2）who am i （功能描述：显示登录用户的用户名以及登陆时间）2）案例实操
（1）显示自身用户名称
[root@hadoop101 opt]# whoami
（2）显示登录用户的用户名
[root@hadoop101 opt]# who am i

7.4.9 usermod 修改用户
1）基本语法
usermod -g 用户组 用户名
2）选项说明
选项 功能
-g 修改用户的初始登录组，给定的组必须存在。默认组id 是1。
3）案例实操
（1）将用户加入到用户组
[root@hadoop101 opt]# usermod -g root zhubajie



--其他用户组管理命令
每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，
如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。
用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。

7.5.1 groupadd 新增组
1）基本语法
groupadd 组名
2）案例实操
（1）添加一个xitianqujing组
[root@hadoop101 opt]#groupadd xitianqujing

7.5.2 groupdel 删除组
1）基本语法
groupdel 组名
2）案例实操
（1）删除xitianqujing组
[root@hadoop101 opt]# groupdel xitianqujing

7.5.3 groupmod 修改组
1）基本语法
groupmod -n 新组名 老组名
1）选项说明

选项 功能描述
-n<新组名> 指定工作组的新组名
3）案例实操
（1）修改atguigu组名称为atguigu1
[root@hadoop101 ~]#groupadd xitianqujing
[root@hadoop101 ~]# groupmod -n xitian xitianqujing

7.5.4 cat /etc/group 查看创建了哪些组
1）基本操作
[root@hadoop101 atguigu]# cat /etc/group


--------------------------- <-->04.文件权属类命令---------------------

--关于linux系统的文件属性
Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。
为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。
在Linux中我们可以使用ll或者ls -l命令来显示一个文件的属性以及文件所属的用户和组。


drwxr-xr-x.

从左到右的 10 个字符表示文件属性
如果没有权限，就会出现减号[ - ]而已。从左至右用0-9这些数字来表示:

（1）0 首位表示类型
在Linux中第一个字符代表这个文件是目录、文件或链接文件等等
- 代表文件
d 代表目录
l 链接文档(link file)；
（2）第1-3位确定属主（该文件的所有者）拥有该文件的权限。---User
（3）第4-6位确定属组（所有者的同组用户）拥有该文件的权限，---Group
（4）第7-9位确定其他用户拥有该文件的权限 ---Other

2）rwx 作用文件和目录的不同解释
（1）作用到文件：
[ r ]代表可读(read): 可以读取，查看
[ w ]代表可写(write): 可以修改，但是不代表可以删除该文件，删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件.
[ x ]代表可执行(execute):可以被系统执行

（2）作用到目录：
[ r ]代表可读(read): 可以读取，ls查看目录内容
[ w ]代表可写(write): 可以修改，目录内创建+删除+重命名目录[ x ]代表可执行(execute):可以进入该目录
[ x ]代表可执行(execute):可以进入该目录

3）案例实操
[root@hadoop101 ~]# ll
总用量 104
-rw-------. 1 root root 1248 1 月 8 17:36 anaconda-ks.cfg
drwxr-xr-x. 2 root root 4096 1 月 12 14:02 dssz
lrwxrwxrwx. 1 root root 20 1 月 12 14:32 houzi -> xiyou/dssz/houge.tx
（1）如果查看到是文件：链接数指的是硬链接个数。
（2）如果查看的是文件夹：链接数指的是子文件夹个数。


<-->25.chmod 改变权限  change modal(改变形式)

1）基本语法
drwxr-xr-x

第一种方式变更权限
chmod [{ugoa}{+-=}{rwx}] 文件或目录

u:所有者 g:所有组 o:其他人 a:所有人(u、g、o 的总和)

第二种方式变更权限
chmod [mode=421 ] [文件或目录]

r=4 w=2 x=1 rwx=4+2+1=7

2）案例实操

（1）修改文件使其所属主用户具有执行权限
[root@hadoop101 ~]# cp xiyou/dssz/houge.txt ./
[root@hadoop101 ~]# chmod u+x houge.txt

（2）修改文件使其所属组用户具有执行权限
[root@hadoop101 ~]# chmod g+x houge.txt

（3）修改文件所属主用户执行权限,并使其他用户具有执行权限
[root@hadoop101 ~]# chmod u-x,o+x houge.txt

--修改其他用户拥有读写执行权限
[zhangjian@hadoop102 study]$ chmod o=rwx flink 
[zhangjian@hadoop102 study]$ ll
总用量 52
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:31 dalian
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark


（4）采用数字的方式，设置文件所有者、所属组、其他用户都具有可读可写可执行权限。
[root@hadoop101 ~]# chmod 777 houge.txt

（5）修改整个文件夹里面的所有文件的所有者、所属组、其他用户都具有可读可写可执行权限。
[root@hadoop101 ~]# chmod -R 777 xiyou/

--修改多个文件的权限
chmod +x 111.sh 22.sh 

-- *来匹配后面都一样的文件也可以
chmod +x hdfs_to_ods* 


<-->26.chown 改变所有者  change own

1）基本语法
chown [选项] [最终用户] [文件或目录] （功能描述：改变文件或者目录的所有者）

2）选项说明

选项 功能
-R 递归操作

3）案例实操

（1）修改文件所有者
[root@hadoop101 ~]# chown atguigu houge.txt
[root@hadoop101 ~]# ls -al
-rwxrwxrwx. 1 atguigu root 551 5 月 23 13:02 houge.txt

（2）递归改变文件所有者和所有组
[root@hadoop101 xiyou]# ll
drwxrwxrwx. 2 root root 4096 9 月 3 21:20 xiyou
[root@hadoop101 xiyou]# chown -R atguigu:atguigu xiyou/
[root@hadoop101 xiyou]# ll
drwxrwxrwx. 2 atguigu atguigu 4096 9 


<-->27.chgrp 改变所属组  change group

1）基本语法
chgrp [最终用户组] [文件或目录] （功能描述：改变文件或者目录的所属组）

2）案例实操
（1）修改文件的所属组
[root@hadoop101 ~]# chgrp root houge.txt
[root@hadoop101 ~]# ls -al
-rwxrwxrwx. 1 atguigu root 551 5 月 23 13:02 houge.txt


--------------------<-->05.搜索查找类命令-------------------------------------------

<-->28.find 查找文件或者目录

find 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件显示在终端。

1）基本语法
find [搜索范围] [选项]

2）选项说明
选项 功能
-name<查询方式> 按照指定的文件名查找模式查找文件
-user<用户名> 查找属于指定用户名所有文件
-size<文件大小> 按照指定的文件大小查找文件,单位为:
b —— 块（512 字节）
c —— 字节
w —— 字（2 字节）
k —— 千字节
M —— 兆字节
G —— 吉字节

3）案例实操

（1）按文件名：根据名称查找/目录下的filename.txt文件。
[root@hadoop101 ~]# find xiyou/ -name "*.txt" 

（2）按拥有者：查找/opt目录下，用户名称为-user的文件
[root@hadoop101 ~]# find xiyou/ -user atguigu 

（3）按文件大小：在/home目录下查找大于200m的文件（+n 大于-n小于n等于）
[root@hadoop101 ~]find /home -size +204800


<-->29.locate 快速定位文件路径

locate 指令利用事先建立的系统中所有文件名称及路径的 locate 数据库实现快速定位给定的文件。
Locate 指令无需遍历整个文件系统，查询速度较快。
为了保证查询结果的准确度，管理员必须定期更新 locate 时刻。

1）基本语法
locate 搜索文件

2）经验技巧
由于 locate 指令基于数据库进行查询，所以第一次运行前，必须使用updatedb 指令创建 locate 数据库。

3）案例实操
（1）查询文件夹 --locate tmp  使用该命令会跳出很多文件，谨慎使用
[root@hadoop101 ~]# updatedb
[root@hadoop101 ~]#locate tmp

--权限不足会报以下错误
[zhangjian@hadoop102 study]$ updatedb
updatedb: 无法为 `/var/lib/mlocate/mlocate.db' 打开临时文件


<-->030.grep 过滤查找及“|”管道符

管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理

-------------------<-->关于正则表达式------------------
一、正则表达式概述

正则表达式定义:
正则表达式，又称正规表达式、常规表达式
使用字符串来描述、匹配一系列符合某个规则的字符串
简单来说，是一种匹配字符串的方法，通过一些特殊符号，实现快速查找、删除、替换某个特定字符串。

正则表达式组成:
普通字符：大小写字母、数字、标点符号及一些其他符号
元字符：在正则表达式中具有特殊意义的专用字符

正则表达式的用途:
正则表达式对于系统管理员来说是非常重要的，系统运行过程中会产生大量的信息，
这些信息有些是非常重要的，有些则仅是告知的信息。
身为系统管理员如果直接看这么多的信息数据，无法快速定位到重要的信息，
如“用户账号登录失败”“服务启动失败”等信息。
这时可以通过正则表达式快速提取“有问题”的信息。
如此一来，可以将运维工作变得更加简单、方便。

所谓正则表达式，实际上就是用来描述某些字符串匹配规则的工具。
由于正则表达式语法简练，功能强大，得到了许多程序设计语言的支持，包括Java、C++、Perl以及Shell等。

一个正则表达式是一个字符串.字符串里的字符被称为元字符,它们可能表示了比它们字面上看起来的意思更丰富的含义.
例如,一个引用符号可能表示引用一个人演讲中的话,或者表示下面将要讲到的，
引申表示的意思.正则表达式是一个字符或/和元字符组合成的字符集,它们匹配(或指定)一个模式

在进行程序设计的过程中，用户会不可避免地遇到处理某些文本的情况。
有的时候，用户还需要查找符合某些比较复杂规则的字符串。
对于这些情况，如果单纯依靠程序设计语言本身，则往往会使得用户通过复杂的代码来来实现。
但是，如果使用正则表达式，则会以非常简短的代码来完成。

当一个正则表达式完成之后，并能够保证这个表达式一定是准确的，需要不断地测试才可以确定其正确与否。
在不同的环境下，用户需要不同的工具来帮助他完成测试的过程。如果是在Shell命令行中，用户可以使用grep命令来测试。

一个正则表达式包含下面一个或多个项:

一个字符集.
这里的字符集里的字符表示的就是它们字面上的意思.正则表达式最简单的情况就是仅仅由字符集组成,而没有其他的元字符.
锚.
一个锚指明了正则表达式在一行文本中要匹配的位置,例如^和$就是锚.
修饰符
它们用于展开或缩小(即是修改了)正则表达式匹配文本行的范围.修饰符包括了星号. 括号和反斜杠符号.
正则表达是的主要作用是用来文本搜索和字串操作.一个正则表达式匹配一个字符或是一串字符–完整的一串字符或是另外一个字符串的子串.

正则表达式分类:
基础正则表达式
扩展正则表达式

Linux中文本处理工具:
支持基础正则表达式：grep；sed
支持扩展正则表达式：egrep；awk

--------基本正则表达式
基本正则表达式（Basic Regular Expression，BRE），又称为标准正则表达式，是最早制订的正则表达式规范，仅支持最基本的元字符集。
基本正则表达式是POSIX规范制订的两种正则表达式语法标准之一，另外一种语法标准称为扩展正则表达式，将在随后介绍。
基本正则表达式所定义的元字符主要有以下几种。

1．行首定位符“^”
是正则表达式中的定位符之一，用来匹配行首的字符，表示行首的字符是“^”后面的那个字符。
正则表达式中的定位符的作用与其他的元字符不同，它们不是用来匹配具体的文本，而是匹配某个具体的位置，
例如行首定位符“^”就是用来匹配文本行的开头的字符的。

2．行尾定位符“$”
与行首定位符的作用恰恰相反，行尾定位符的作用是用来定位文本行的末尾的。
从语法上讲，行尾定位符的位置也与行首定位符相反，行首定位符位于所作用的字符之前，
而行尾定位符位于所作用的字符之后。"^$" 匹配空行.

3．单个字符匹配“.”
圆点“.”用来匹配任意单个字符，包括空格，但是不包括换行符“\n”。当用户使用“.”符号后，
意味着该位置一定有一个字符，无论它是什么字符。“13.” 匹配 13 + 至少一个任意字符(包括空格): 1133, 11333, 
但不匹配 13(因为少了附加的至少一个任意字符).

4．限定符“*”
星号“*”是正则表达式中的限定符之一。限定符本身不代表任何字符，它是用来指定其前面的一个字符必须要重复出现多少次才能满足匹配。
星号“*”表示匹配其前导字符的任意次数，包括0次."1133*"匹配 11 + 一个或更多的 3 + 可能的其他字符: 113, 1133, 111312, 等等.

5．字符集匹配“[ ]”
方括号“[ ]”的功能比较特殊，它是用来指定一个字符集合的，其基本语法为：
[abc]
其中a、b和c表示任意的单个字符。如果某个字符串在方括号所在的位置上出现了方括号中的任意一个字符，都是满足匹配规则。
另外，对于连续的数字或者字母，可以使用连字符“-”来表示一个范围，例如“[a-f]”表示匹配字母表中a到f中的任意一个字母。
而“[0-9]”表示匹配任意单个数字。"[B-Pk-y]" 匹配从 B 到 P 或从 k 到 y 的任意一个字符. “[^b-d]” 
匹配除了从 b 到 d 范围内所有的字符. 这是正则表达式中反转意思或取否的一 个例子.(就好像在别的情形中!字符所扮演的角色).
多个方括号字符集组合使用可以匹配一般的单词和数字模式."[Yy][Ee][Ss]" 匹配 yes, Yes, YES, yEs, 等等.
"[0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]"匹配社会安全码(Social Security number)

6．字符集不匹配“[^]”
前面已经介绍过行首定位符“^”和字符集匹配符“[ ]”。但是如果将这2个符号结合起来，则其意义会发生变化。
符号“[^]”表示不匹配其中列出的任意字符，其语法如下：
[^abc]
其中a、b和c表示任意的单个字符。“[^]”符号的用法与符号“[ ]”的用法相同，不再举例说明。
除了前面介绍的6个元字符之外，在基本正则表达式中还定义了其他的一些元字符。这些元字符使用较少，
语法较繁琐，且在扩展正则表达式和PERL正则表达式中都有替代的元字符，所以不再详细说明。表中列出了基本正则表达式的其他的元字符。

7.反斜杠字符
\转义(escapes) 一个特殊的字符,使这个字符表示原来字面上的意思.
“\$“表示了原来的字面意思”$”,而不是在正则表达式中表达的匹配行尾的意思.
同样,"\\“也被解释成了字面上的意思”\".

8.转义(escape)“尖角号”\<…\>
用于表示单词的边界. 尖角号必须被转义,
因为不这样做的话它们就表示单纯的字面意思而已."\<the\>" 匹配单词"the",但不匹配"them", “there”, “other”, 等等.

-----扩展正则表达式
扩展正则表达式（Extended Regular Expression，ERE）支持比基本正则表达式更多的元字符，
但是扩展正则表达式对有些基本正则表达式所支持的元字符并不支持。
上文中介绍的元字符“^”、“$”、“.”、“*”、“[]”以及“[^]”这6个元字符在扩展正则表达式都得到了支持，
并且其意义和用法都完全相同，不再重复介绍。接下来重点介绍一下在扩展正则表达式中新增加的一些元字符。

1．限定符“+”
匹配一个或多个前面的字符.它的作用和*很相似,但唯一的区别是它不匹配零个字符的情况.
echo a111b | grep ‘a1\+b’
echo a111b | gawk ‘/a1+b/’
echo a111b | sed -ne ‘/a1\+b/p’
这三句的效果都等同

【例7】演示加号“+”的使用方法
#! /bin/bash
#筛选以字符串“ss”开头，后面至少紧跟着1个字符“s”的文本行
str=`ls /etc | egrep "^sss+"`
echo "$str"

运行以上程序

[root@localhost ~]# touch /etc/sssd
[root@localhost ~]# ./test.sh
sssd

2．限定符“?”
问号“?”是另外一个限定符，它用来限定前面的字符最多只出现1次，即前面的字符可以重复0次或者1次。
【例8】演示问号通配符的使用方法

#! /bin/bash
#筛选以字符串“ss”开头，后面跟着0或者1个s的文本行
str=`ls /etc | egrep "^sss?"`
echo "$str"

运行以上程序

[root@localhost ~]# ./test.sh
ssh
ssl
sssd

3．竖线“|”和圆括号“()”
竖线“|” 表示多个正则表达式之间“或”的关系，其语法为：
expression1|expression2|e=xpression3|…|expressionn
圆括号“()”用来表示一组可选值的集合。竖线和圆括号经常在一起使用，表示一组可选值。

4．转义"大括号"{ }指示前面正则表达式匹配的次数.
要转义是因为不转义的话大括号只是表示他们字面上的意思.这个用法只是技巧上的而不是基本正则表达式的内容.
“[0-9]\{5\}” 精确匹配 5 个数字 (从 0 到 9 的数字).
注意：大括号不能在“经典”(不是 POSIX 兼容)的正则表达式版本的 awk 中使用. 
然而, gawk 有一个选项- -re-interval 来允许使用大括号(不必转义).
bash$ echo 2222 | gawk --re-interval ‘/2{3}/’
2222
【例9】演示圆括号和竖线的使用方法

#! /bin/bash
#筛选含有字符串“ssh”、“ssl”或者以字符串“yum”开头的文本行
#grep -E主要是用来支持扩展正则表达式
#grep -E =egrep
str=`ls /etc | egrep "(ssh|ssl|^yum)"`
echo "$str"

运行以上程序

[root@localhost ~]# ./test.sh
ssh
ssl
yum
yum.conf
yum.repos.d
----------------------------
正则表达式应用
匹配单个字符
在正则表达式中，可以用来匹配单个字符的表达式大致有4种，分别是单个一般字符、转义后的元字符、圆点“.”表达式以及方括号表达式。下面分别进行介绍。
1．单个一般字符
所谓一般字符，是指除了正则表达式中已经定义的元字符之外的所有字符，例如英文字符、数字、空白字符以及标点符号等。这些一般字符组正则表达式中都只是表达它们自身的字面意义，没有其他额外的意义。当需要匹配某个一般字符时，可以直接将该字符作为表达式或者是表达式的一部分。
【例11】演示如何使用普通字符作为表达式来匹配单个字符

#! /bin/bash
#搜索含有字符“a”的文本行
str=`grep "a" demo2.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# cat demo2.txt 
a1234
nihaoya
hhhhh
nishishei
hello,abc
[root@localhost ~]# ./test.sh
a1234
nihaoya
hello,abc
1
2
3
4
5
6
7
8
9
10
2．转义后的元字符
在前面介绍基本正则表达式、扩展正则表达式以及Perl正则表达式的时候，都介绍了一些元字符。如果想要匹配这些元字符本身，则需要在这些字符的前面加上转义字符“\”。通过这样操作，可以关闭这些元字符的特殊意义，而只保留其字面意义。
例如，如果想要匹配圆点“.”就可以使用表达式“\.”。经过转义之后，这个表达式就表示一个圆点符号，而不是任意单个字符。如果想要匹配其他的元字符，例如问号“?”，同样可以使用表达式“\?”。
【例12】演示直接使用元字符圆点作为表达式，则会导致匹配结果出错

#! /bin/bash
str=`grep "." demo3.txt`	#匹配出错
echo "$str"
echo "======================="
str=`grep "\." demo3.txt`	#匹配有.的行
echo "$str"
1
2
3
4
5
6
运行以上程序

[root@localhost ~]# ./test.sh
No matter what you're looking for, our motto is "keep it simple" 
Start by entering a basic name or word. 
If you're looking for a place or product in a specific location, 
enter the name along with the town or zip code.
=======================
Start by entering a basic name or word. 
enter the name along with the town or zip code.
1
2
3
4
5
6
7
8
3．圆点表达式
圆点“.”表示匹配任意单个字符，除了换行符之外。关于圆点表达式的使用方法，请参见例4，不再重复介绍。
4．方括号表达式
前面已经介绍过，方括号表达式用来表示一个可选字符的集合。尽管通常情况下，在方括号中含有多个字符，但是一次只能从这些字符中选择一个，因此，方括号表达式仍然表示的是匹配单个字符。例如，表达式“[abc]”就表示匹配字符“a”、“b”或者“c”中的任意一个。同时，这种表示方法也是最简单的一种形式，也就是直接将所要匹配的字符都在方括号中罗列出来。
如果在方括号中的字符列表前面加上符号“^”，则表示取反的意思。也就是说，不匹配方括号中列出来的任何一个字符。例如，表达式“[^abc]”表示不匹配“a”、“b”和“c”这3个字符中的任何一个。

匹配多个字符
正则表达式可以使用多种方法来匹配多个字符，其中最简单的一种就是将多个字符按照指定的顺序拼接起来。
【例13】演示如何匹配一个有多个字符组成的字符串

#! /bin/bash
#搜索字符串“matter”
str=`grep "matter" demo3.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# ./test.sh
No matter what you're looking for, our motto is "keep it simple" 
1
2
【例14】演示如何将普通字符和方括号表达式混合起来使用

#! /bin/bash
#匹配含有字符“o”，后面紧跟着字符“r”或者“u”的文本行
str=`grep "o[ru]" demo3.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# ./test.sh
No matter what you're looking for, our motto is "keep it simple" 
Start by entering a basic name or word. 
If you're looking for a place or product in a specific location, 
enter the name along with the town or zip code.
1
2
3
4
5
【例15】使用星号来匹配多个字符“o”

#! /bin/bash
#匹配任意多个字符“o”
str=`grep "lo*king" demo3.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# ./test.sh
No matter what you're looking for, our motto is "keep it simple" 
If you're looking for a place or product in a specific location, 
1
2
3
【例16】演示如何通过正则表达式来筛选符合指定格式的电话号码

#! /bin/bash
#筛选符合格式的电话号码
str=`egrep "800-[[:digit:]]{3}-[[:digit:]]{4}$" demo4.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# cat demo4.txt 
A:800-820-1100
B:800-820-0323
C:800-820-6655
D:800-810-2288
HH:800-123-6666
HA:800-456-222
E:720-3210-1100
F:450-432-0323
G:420-4555-665
H:230-4847-228
[root@localhost ~]# ./test.sh
A:800-820-1100
B:800-820-0323
C:800-820-6655
D:800-810-2288
HH:800-123-6666
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
【例17】演示如何使用行首定位符筛选数据行

#! /bin/bash
#筛选以3个数字开头的文本行
str=`egrep "^[[:digit:]]{3}" demo5.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# cat demo5.txt
1342343
14325-23544
4332-234
23
234
1-42341342343
[root@localhost ~]# ./test.sh
1342343
14325-23544
4332-234
234
1
2
3
4
5
6
7
8
9
10
11
12
【例18】演示行尾定位符的使用方法

#! /bin/bash
#筛选以4个数字结尾的文本行
str=`egrep "[[:digit:]]{4}$" demo5.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# ./test.sh
1342343
14325-23544
1-42341342343
1
2
3
4
子表达式
所谓子表达式，是指由多个普通字符或者元字符组成的一个小的正则表达式。与正则表达式一样，子表达式本身也是一个完整的表达式，但是在使用时，子表达式是作为一个大的正则表达式的一部分来使用的，而不是单独使用。在正则表达式中，子表达式作为一个整体来看待。子表达式使用圆括号()括起来。
【例19】通过正则表达式定位所有的2个连续的HTML空格符

#! /bin/bash
str=`egrep "&nbsp;{2}" html.txt`
echo "$str"
1
2
3
运行以上程序

[root@localhost ~]# cat html.txt
&nbsp;&nbsp;
&nbsp;;&nbsp;;
&nbsp;;
&nbsp;
&nbsp;;hhhhhh&nbsp;;
&nbsp;kkkk&nbsp;
[root@localhost ~]# ./test.sh
&nbsp;;&nbsp;;
&nbsp;;
&nbsp;;hhhhhh&nbsp;;
1
2
3
4
5
6
7
8
9
10
11
【例20】演示通过正则表达式匹配IP地址的方法

#! /bin/bash
#匹配IP地址
str=`egrep "^([[:digit:]]{1,3}\.){3}[[:digit:]]{1,3}$" ip.txt`
echo "$str"
1
2
3
4
运行以上程序

[root@localhost ~]# cat ip.txt
202.116.3.2
10.0.0.1
256.45.2.1
123.354.78.34
243.324.3423.234
6732.2386.78.4
[root@localhost ~]# ./test.sh
202.116.3.2
10.0.0.1
256.45.2.1
123.354.78.34
1
2
3
4
5
6
7
8
9
10
11
12
【例21】通过正则表达式分别对IP地址的4组数字都给出明确的匹配规则


1
运行以上程序


1
通配符
Shell使用了正则表达式中的某些元字符作为其通配符，常用的有*、?、[]、{}以及^等。这些字符在Shell中的意义与在正则表达式中的意义有些区别，例如*表示匹配任意的字符，而非正则表达式中的限制其前导字符的0次或者多次重复。?表示一个字符，而非其前导字符的0次或者1次重复。
如果用户想要列出以h开头的当前目录中所有的文件，可以使用以下命令：

[root@localhost ~]# ls -l h*
-rw-r--r--. 1 root root 66 Jun 20 07:30 hello.txt
-rw-r--r--. 1 root root 81 Jun 20 09:44 html.txt
1
2
3
如果想要列出以字符d或者h开头的文件名，则可以使用方括号将这些字符列出来，如下：

[root@localhost ~]# ls -l [dh]*
-rw-r--r--. 1 root root  40 Jun 20 09:06 demo2.txt
-rw-r--r--. 1 root root 221 Jun 20 09:11 demo3.txt
-rw-r--r--. 1 root root 152 Jun 20 09:37 demo4.txt
-rw-r--r--. 1 root root  50 Jun 20 09:33 demo5.txt
-rw-r--r--. 1 root root  29 Jun 20 07:52 dian.txt
-rw-r--r--. 1 root root  66 Jun 20 07:30 hello.txt
-rw-r--r--. 1 root root  81 Jun 20 09:44 html.txt
1
2
3
4
5
6
7
8
在某些情况下，文件名是按照字母或者数字顺序来编号的，在这种情况下，用户可以使用连字符来表示一个范围，这与正则表达式中的表达方法是一致的，如下：

[root@localhost ~]# ls -l demo[0-9].txt
-rw-r--r--. 1 root root  40 Jun 20 09:06 demo2.txt
-rw-r--r--. 1 root root 221 Jun 20 09:11 demo3.txt
-rw-r--r--. 1 root root 152 Jun 20 09:37 demo4.txt
-rw-r--r--. 1 root root  50 Jun 20 09:33 demo5.txt


----------------------------

基础正则表达式元字符:
基础正则表达式是常用的正则表达式部分
除了普通字符外，常见到以下元字符 

■ \  ：转义字符，\!、 \n等     #让特殊意义的元字符作普通字符使用  
■ ^ ：匹配字符串开始的位置  
例: ^a、 ^the、 ^#  
■ $ ：匹配字符串结束的位置  
例: word$  
■  . ：匹配除\n之外的任意的一个字符  
 例: go.d、 g..d  
■  * ：匹配前面子表达式0次或者多次  
 例: goo*d、 go.*d  
■ [list] ：匹配list列表中的一个字符  
 例: go[ola]d 、[abc]、 [a-z]、 [a-z0-9]  
■ [^list] ：匹配任意不在list列表中的一个字符  
 例: [^a-z]、 [^0-9]、 [^A-Z0-9]  
■ \{n,m\} ：匹配前面的子表达式n到m次，有\{n\}、 \{n,\}、\{n,m\}三种格式  
 例: go\{2\}d、 go\{2,3\}d、 go\{2,\}d  
 注意：“o｛1,}” 等价于 “o+”  ；“o{0,}” 则等价于 “o*” 
---------------------------------------------------

-------------------<-->关于通配符----------------------
1、通配符
在Bash中，如果需要模糊匹配文件名或目录名，就要用到通配符。
下面为常用的通配符。

通配符	说明
*	匹配0或任意个字符
？	匹配一个任意字符
[-]	匹配中括号的字符。例如[a-b]，匹配小写字母，只会匹配集合中的一个
[^]	匹配除了中括号的一个字符。例如[^0-9]，匹配除了数字的字符，只会匹配集合中的一个
{ab,ba}	匹配其中一个字符串。例如匹配ab或ba

---------------------------------------------------

---------------<-->通配符和正则表达式的区别------------
容易混淆的通配符和正则表达式

----区别1：

通配符：匹配文件名
正则表达式：匹配文件中的内容

误区：
例1、查找文件名时，常用正则表达式
#查找mv开头文件，通配符用法
[root@VM_0_6_centos tmp]# ll -d mv*
drwxr-xr-x 2 root root 4.0K Feb 24 17:32 mv2
-rw-r--r-- 1 root root    0 May 14 12:07 mva
-rw-r--r-- 1 root root    0 May 14 12:09 mvabc
#如果正则用法，会查找不到文件
[root@VM_0_6_centos tmp]# ll -d mv.*
ls: cannot access mv.*: No such file or directory

例2、查找文件内容时，用的是正则，例如常用Linux三剑客之一的grep
#查找def开头的行
[root@VM_0_6_centos DCBreakfast]# grep ^def view.py 
def effective_user(request):
def download_apk(request):
def ftpserver_version(request):


----区别2：

通配符：匹配完整的文件名
正则表达式：匹配部分文本

例1：正则在abab字符串中查找a字符
[root@VM_0_6_centos tmp]# grep a mva
abab

----区别3：
正则表达式的*和？量词和通配符不一样

--关于转义特殊字符
通配符是在Shell中有特殊含义的字符，例如*是代表着匹配0或任意个字符，那么这些字符就无法代表它们本身。
如果要使用这些特殊字符本身的意义，使用转义符反斜杠：\


<-->031 grep
1）+语法
grep 选项 查找内容 源文件

2）选项说明
选项 功能
-n 显示匹配行及行号
-i 表示不区分大小写
-v 表示反向过滤
[ ] 查找集合字符

2）用法示例 

grep -n 'the' test.txt     #文件检索出带‘the’的行并显示行号  
grep -vn 'the' test.txt   #文件反向检索出不带‘the’的行并显示行号  
grep -n 'sh[oi]rt' test.txt  #文件检索出带‘short’或‘shirt‘的行并显示行号  
grep -n 'oo' test.txt   #文件检索出至少带连续oo的行并显示行号  
grep -n 'o\{2\}' test.txt   #文件检索出至少带连续oo的行并显示行号  
grep -n 'o\{2,\}' test.txt   #文件检索出至少带连续oo的行并显示行号  
grep -n '[^w]oo' test.txt   #文件检索出连续oo前面不带w的行并显示行号  
grep -n '^[^w]oo' test.txt  #文件检索出除w外，任意*oo开头的行并显示行号  
grep -n ' [^a-z]oo ' test.txt  #文件检索出连续oo前面不是小写字母的行并显示行号  
grep -n '[0-9]' test.txt    #文件检索出包含数字的行并显示行号  
grep -n '[^0-9]' test.txt  #文件检索出不包含纯数字的行并显示行号，非纯数字也会匹配  
grep -n '[^#]' test.txt   #文件检索出不包含#的行并显示行号  
grep -n '^the' test.txt  #文件检索出以‘the’开头的行并显示行号  
grep -n ‘^[a-z] ' test.txt   #文件检索出以小写字母开头的行并显示行号  
grep -n ‘^[A-Z] ' test.txt   #文件检索出以大写字母开头的行并显示行号  
grep -n '^[^a-zA-Z]' test.txt   #文件检索出不以字母开头的行并显示行号  
grep -n '\.$' test.txt  #文件检索出以 . 号结尾的行并显示行号  
grep -n '^$' test.txt   #文件检索出空行并显示行号  
grep -n 'w..d' test.txt  #文件检索出带有w开头，d结尾，中间两个任意字符的行并显示行号  
grep -n 'ooo*' test.txt  #文件检索出带有连续oo或两个0以上的行并显示行号  
grep -n 'oo*' test.txt  #文件检索出带有o或一个0以上的行并显示行号  
grep -n 'w.*d' test.txt   #文件检索出带有w开头，d结尾，中间任意字符也可中间什么也没有的行并显示行号  
grep -n '[0-9][0-9]*' test .txt  #文件检索出带有数字的行并显示行号 

3）案例实操

--精确查找 查找某文件在第几行
[zhangjian@hadoop102 study]$ ll | grep -n shenzhen
12:drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen

--和重定向配合使用
[zhangjian@hadoop102 study]$ ll | grep -n shenzhen > test.txt 
[zhangjian@hadoop102 study]$ head test.txt 
12:drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen

--过滤出带有root的行并显示行号
[zhangjian@hadoop102 study]$ grep -n 'root' /etc/passwd
1:root:x:0:0:root:/root:/bin/bash
10:operator:x:11:0:operator:/root:/sbin/nologin

----其他参数
-b   在搜索到的行的前面打印该行所在的块号码。
-c   只显示有多少行匹配 ，而不具体显示匹配的行
-h   不显示文件名
-i    在字符串比较的时候忽略大小写
-l    只显示包含匹配模板的行的文件名清单，不同项目之间用换行符分隔
-L   打印不匹配模板的文件名清单
-n   在每一行前面打印该行在文件中的行数
-s   静默工作，除非出现错误信息否则不打印任何信息，这个功能在检测退出状态的时候有用
-v   反检索，只显示不匹配的行
-w 
-Ax  在匹配指定行打印完毕后，再打印x行(向原文件匹配行下x行)
-By  在匹配指定行前面打印y行(在原文件匹配行上面打印y行)
-Cz  在匹配行前后打印z行  (在原文件匹配行上下打印z行)
-b    在每一行前面打印字符偏移量
-f  file   从文件file中提取模板。空文件中包含0个模板
-q     取消标准输出，跟-n功能是一样的
-s     不显示关于不存在或者无法读文件的错误信息
-w   只打印以单词形式匹配模板的行，模板可以是包含数字、字符和下划线的字符串
-x    只打印整行匹配的行
-y   用法同-i
-U  把文件作为二进制文件，这个选项只在MS－DOS和MS－Windows中被支持(这个参数没有明白，请过路高人指点，非常感谢)
-u 按照unix风格报告字符偏移量。只在-b选项同时被使用的时候才有效。这个选项只在MS－DOS和MS－Windows中被支持
-----------------------------------

--------------------------- <-->06.压缩和解压类命令-----------------------


<-->30.gzip/gunzip 压缩

1）基本语法
gzip 文件 （功能描述：压缩文件，只能将文件压缩为*.gz 文件）
gunzip 文件.gz （功能描述：解压缩文件命令）

2）经验技巧
（1）只能压缩文件不能压缩目录
（2）不保留原来的文件
（3）同时多个文件会产生多个压缩包

3）案例实操
（1）gzip压缩
[root@hadoop101 ~]# ls
test.java
[root@hadoop101 ~]# gzip houge.txt
[root@hadoop101 ~]# ls
houge.txt.gz 
（2）gunzip解压缩文件
[root@hadoop101 ~]# gunzip houge.txt.gz
[root@hadoop101 ~]# ls
houge.txt


<-->31.zip/unzip 压缩

1）基本语法
zip [选项] XXX.zip 将要压缩的内容 （功能描述：压缩文件和目录的命令）
unzip [选项] XXX.zip （功能描述：解压缩文件）

2）选项说明

zip 选项 功能
-r 压缩目录

unzip 选项 功能
-d<目录> 指定解压后文件的存放目录

3）经验技巧
zip 压缩命令在windows/linux都通用，可以压缩目录且保留源文件。

4）案例实操

（1）压缩 houge.txt 和bailongma.txt，压缩后的名称为mypackage.zip

[root@hadoop101 opt]# touch bailongma.txt
[root@hadoop101 ~]# zip mypackage.zip houge.txt bailongma.txt
adding: houge.txt (stored 0%)
adding: bailongma.txt (stored 0%)
[root@hadoop101 opt]# ls
houge.txt bailongma.txt mypackage.zip

----压缩文件的方式
[zhangjian@hadoop102 study]$ ll
总用量 56
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:31 dalian
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt
[zhangjian@hadoop102 study]$ zip -r dalian_22.zip dalian/
  adding: dalian/ (stored 0%)
  adding: dalian/ll.sl (stored 0%)
  adding: dalian/111 (stored 0%)
  adding: dalian/dsa.txt (stored 0%)
  adding: dalian/ganjingzi/ (stored 0%)
[zhangjian@hadoop102 study]$ ll
总用量 60
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 3 zhangjian zhangjian    62 6月  24 16:41 dalian
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:41 dalian_22.zip
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt

------名称相同则会覆盖
[zhangjian@hadoop102 study]$ ll
总用量 60
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 3 zhangjian zhangjian    62 6月  24 16:41 dalian
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:41 dalian_22.zip
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt
[zhangjian@hadoop102 study]$ zip -r dalian_22.zip dalian/
updating: dalian/ (stored 0%)
updating: dalian/ll.sl (stored 0%)
updating: dalian/111 (stored 0%)
updating: dalian/dsa.txt (stored 0%)
updating: dalian/ganjingzi/ (stored 0%)
[zhangjian@hadoop102 study]$ zip -r dalian_22.zip dalian/^C
[zhangjian@hadoop102 study]$ ll
总用量 60
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 3 zhangjian zhangjian    62 6月  24 16:41 dalian
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:42 dalian_22.zip
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt

-----且无论怎么命名，文件名都是*.zip
[zhangjian@hadoop102 study]$ ll
总用量 60
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 3 zhangjian zhangjian    62 6月  24 16:41 dalian
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:42 dalian_22.zip
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt
[zhangjian@hadoop102 study]$ zip -r dalian_21 dalian/
  adding: dalian/ (stored 0%)
  adding: dalian/ll.sl (stored 0%)
  adding: dalian/111 (stored 0%)
  adding: dalian/dsa.txt (stored 0%)
  adding: dalian/ganjingzi/ (stored 0%)
[zhangjian@hadoop102 study]$ ll
总用量 64
drwxrwxr-x. 7 zhangjian zhangjian    79 6月  23 13:22 beijing
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 chongqing
drwxrwxr-x. 3 zhangjian zhangjian    62 6月  24 16:41 dalian
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:43 dalian_21.zip
-rw-rw-r--. 1 zhangjian zhangjian   782 6月  24 16:42 dalian_22.zip
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 eclipse
-rw-rw-rwx. 1 zhangjian zhangjian     0 6月  23 22:23 flink
drwxrwxr-x. 2 zhangjian zhangjian     6 6月  23 22:22 guangzhou
drwxrwxr-x. 3 zhangjian zhangjian    33 6月  23 22:37 hangzhou
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 idea_dalian
drwxrwxr-x. 5 zhangjian zhangjian    51 6月  23 13:22 shanghai
-rw-rw-r--. 1 zhangjian zhangjian 52088 6月  23 23:40 shell命令总结-20220622.txt
drwxrwxr-x. 9 zhangjian zhangjian   109 6月  23 18:28 shenzhen
-rw-rw-r--. 1 zhangjian zhangjian     0 6月  23 22:23 spark
-rw-rw-r--. 1 zhangjian zhangjian    67 6月  24 11:57 test.txt


（2）解压 mypackage.zip

[root@hadoop101 ~]# unzip mypackage.zip
Archive: houma.zip
extracting: houge.txt
extracting: bailongma.txt
[root@hadoop101 ~]# ls
houge.txt bailongma.txt mypackage.zip

（3）解压mypackage.zip到指定目录-d

[root@hadoop101 ~]# unzip mypac


<-->32.tar 打包

1）基本语法
tar [选项] XXX.tar.gz 将要打包进去的内容 （功能描述：打包目录，压缩后的文件格式.tar.gz）

2）选项说明

选项 功能
-c 产生.tar 打包文件
-v 显示详细信息
-f 指定压缩后的文件名
-z 打包同时压缩
-x 解包.tar 文件
-C 解压到指定目录

3）案例实操
（1）压缩多个文件
[root@hadoop101 opt]# tar -zcvf houma.tar.gz houge.txt bailongma.txt
houge.txt
bailongma.txt
[root@hadoop101 opt]# ls
houma.tar.gz houge.txt bailongma.txt
（2）压缩目录
[root@hadoop101 ~]# tar -zcvf xiyou.tar.gz xiyou/
xiyou/
xiyou/mingjie/
xiyou/dssz/
xiyou/dssz/houge.txt
（3）解压到当前目录
[root@hadoop101 ~]# tar -zxvf houma.tar.gz （4）解压到指定目录
[root@hadoop101 ~]# tar -zxvf xiyou.tar.gz -C /opt
[root@hadoop101 ~]# ll /opt/


--------------------------- <-->07.磁盘查看和分区类命令-----------------------

<-->33.du 查看文件和目录占用的磁盘空间du: disk usage 磁盘占用情况

1）基本语法
du 目录/文件 （功能描述：显示目录下每个子目录的磁盘使用情况）

2）选项说明

选项 功能
-h 以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示；
-a 不仅查看子目录大小，还要包括文件
-c 显示所有的文件和子目录大小后，显示总和
-s 只显示总和
--max-depth=n 指定统计子目录的深度为第 n 层

3）案例实操
（1）查看当前用户主目录占用的磁盘空间大小
[root@hadoop101 ~]# du -sh
166M .


<-->34.df 查看磁盘空间使用情况
df: disk free 空余磁盘

1）基本语法
df 选项 （功能描述：列出文件系统的整体磁盘使用量，检查文件系统的磁盘空间占用情况）

2）选项说明
选项 功能
-h 以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示

3）案例实操
（1）查看磁盘使用情况
[root@hadoop101 ~]# df -h
Filesystem Size Used Avail Use% Mounted on
/dev/sda2 15G 3.5G 11G 26% /
tmpfs 939M 224K 939M 1% /dev/shm
/dev/sda1 190M 39M 


<-->35.lsblk 查看设备挂载情况

1）基本语法
lsblk （功能描述：查看设备挂载情况）

2）选项说明

选项 功能
-f 查看详细的设备挂载情况，显示文件系统信息

<-->36.mount/umount 挂载/卸载
对于Linux用户来讲，不论有几个分区，分别分给哪一个目录使用，它总归就是一个根目录、一个独立且唯一的文件结构。
Linux中每个分区都是用来组成整个文件系统的一部分，它在用一种叫做“挂载”的处理方法，
它整个文件系统中包含了一整套的文件和目录，并将一个分区和一个目录联系起来，要载入的那个分区将使它的存储空间在这个目录下获得。

1）挂载前准备（必须要有光盘或者已经连接镜像文件）
2）基本语法
mount [-t vfstype] [-o options] device dir （功能描述：挂载设备）
umount 设备文件名或挂载点 （功能描述：卸载设备）


<-->36.fdisk 分区

1）基本语法
fdisk -l （功能描述：查看磁盘分区详情）
fdisk 硬盘设备名 （功能描述：对新增硬盘进行分区操作）

2）选项说明

选项 功能
-l 显示所有硬盘的分区列表

3）经验技巧
该命令必须在 root 用户下才能使用

4）功能说明
（1）Linux 分区
Device：分区序列
Boot：引导
Start：从X磁柱开始
End：到Y磁柱结束
Blocks：容量
Id：分区类型ID
System：分区类型
（2）分区操作按键说明
m：显示命令列表
p：显示当前磁盘分区
n：新增分区
w：写入分区信息并退出
q：不保存分区信息直接退出

5）案例实操
（1）查看系统分区情况
[root@hadoop101 /]# fdisk -l
Disk /dev/sda: 21.5 GB, 21474836480 bytes
255 heads, 63 sectors/track, 2610 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0005e654
Device Boot Start End Blocks Id System
/dev/sda1 * 1 26 204800 83 Linux
Partition 1 does not end on cylinder boundary.
/dev/sda2 26 1332 10485760 83 Linux
/dev/sda3 1332 1593 2097152 82 Linux swap / Solaris


--------------------------- <-->08.进程管理类命令-----------------------

进程是正在执行的一个程序或命令，每一个进程都是一个运行的实体，都有自己的地址空间，并占用一定的系统资源。

<-->37.ps 查看当前系统进程状态
ps:process status 进程状态

1）基本语法
ps aux | grep xxx （功能描述：查看系统中所有进程）
ps -ef | grep xxx （功能描述：可以查看子父进程之间的关系）

2）选项说明

选项 功能
a 列出带有终端的所有用户的进程
x 列出当前用户的所有进程，包括没有终端的进程u 面向用户友好的显示风格
-e 列出所有进程
-u 列出某个用户关联的所有进程
-f 显示完整格式的进程列表

3）功能说明
（1）ps aux 显示信息说明
USER：该进程是由哪个用户产生的
PID：进程的 ID 号
%CPU：该进程占用 CPU 资源的百分比，占用越高，进程越耗费资源；
%MEM：该进程占用物理内存的百分比，占用越高，进程越耗费资源；
VSZ：该进程占用虚拟内存的大小，单位 KB；
RSS：该进程占用实际物理内存的大小，单位 KB；
TTY：该进程是在哪个终端中运行的。
对于 CentOS 来说，tty1 是图形化终端，tty2-tty6 是本地的字符界面终端。pts/0-255 代表虚拟终端。
STAT：进程状态。常见的状态有：R：运行状态、S：睡眠状态、T：暂停状态、
Z：僵尸状态、s：包含子进程、l：多线程、+：前台显示
START：该进程的启动时间
TIME：该进程占用 CPU 的运算时间，注意不是系统时间
COMMAND：产生此进程的命令名
（2）ps -ef 显示信息说明
UID：用户 ID
PID：进程 ID
PPID：父进程 ID
C：CPU 用于计算执行优先级的因子。
数值越大，表明进程是CPU 密集型运算，执行优先级会降低；
数值越小，表明进程是 I/O 密集型运算，执行优先级会提高
STIME：进程启动的时间
TTY：完整的终端名称
TIME：CPU 时间
CMD：启动进程所用的命令和参数

4）经验技巧
如果想查看进程的 CPU 占用率和内存占用率，可以使用 aux;
如果想查看进程的父进程 ID 可以使用 ef;

5）案例实操
[root@hadoop101 datas]# ps aux

[root@hadoop101 datas]# ps -ef

--查看某个用户关联的所有进程
[zhangjian@hadoop102 study]$ ps -u zhangjian
   PID TTY          TIME CMD
  2044 ?        00:08:11 java
  2177 ?        00:06:04 java
  2501 ?        00:10:33 java
  2689 ?        00:04:42 java
 37308 ?        00:00:00 sshd
 37311 pts/0    00:00:00 bash
 46179 pts/0    00:00:00 ps

<-->38.kill 终止进程

1）基本语法
kill [选项] 进程号 （功能描述：通过进程号杀死进程）
killall 进程名称 （功能描述：通过进程名称杀死进程，也支持通配符，这在系统因负载过大而变得很慢时很有用）

2）选项说明

选项 功能
-9 表示强迫进程立即停止

3）案例实操
（1）杀死浏览器进程
[root@hadoop101 桌面]# kill -9 5102
（2）通过进程名称杀死进程
[root@hadoop101 桌面]# killall firefox


<-->39.pstree 查看进程树

1）基本语法
pstree [选项]

2）选项说明
选项 功能
-p 显示进程的 PID
-u 显示进程的所属用户

3）案例实操
（1）显示进程 pid
[root@hadoop101 datas]# pstree -p
（2）显示进程所属用户
[root@hadoop101 datas]# pstree -u

[zhangjian@hadoop102 study]$ pstree -p
systemd(1)─┬─ModemManager(689)─┬─{ModemManager}(718)
           │                   └─{ModemManager}(753)
           ├─NetworkManager(752)─┬─{NetworkManager}(780)
           │                     └─{NetworkManager}(786)
           ├─VGAuthService(712)
           ├─abrt-watch-log(694)
           ├─abrt-watch-log(755)
           ├─abrtd(690)
           ├─accounts-daemon(706)─┬─{accounts-daemon}(713)
           │                      └─{accounts-daemon}(745)
           ├─alsactl(758)
           ├─at-spi-bus-laun(1397)─┬─dbus-daemon(1408)───{dbus-daemon}(1419)
           │                       ├─{at-spi-bus-laun}(1404)
           │                       ├─{at-spi-bus-laun}(1405)
           │                       └─{at-spi-bus-laun}(1407)
           ├─at-spi2-registr(1423)─┬─{at-spi2-registr}(1430)
           │                       └─{at-spi2-registr}(1432)
           ├─atd(1040)
           ├─auditd(653)─┬─audispd(655)─┬─sedispatch(657)
           │             │              └─{audispd}(658)
           │             └─{auditd}(654)
           ├─avahi-daemon(688)───avahi-daemon(700)
           ├─bluetoothd(697)
           ├─colord(1680)─┬─{colord}(1702)
           │              └─{colord}(1704)
           ├─crond(1044)
           ├─cupsd(1006)
           ├─dbus-daemon(1355)───{dbus-daemon}(1356)
           ├─dbus-daemon(725)───{dbus-daemon}(743)
           ├─dbus-launch(1344)
           ├─dnsmasq(1364)───dnsmasq(1365)
           ├─gdm(1042)─┬─X(1120)───{X}(1253)
           │           ├─gdm-session-wor(1273)─┬─gnome-session-b(1306)─┬─gnome-shell(1482)─┬─ibus-daemon(1580)─┬─ibus-dconf(1584)─┬─+
           │           │                       │                       │                   │                   │                  ├─+
           │           │                       │                       │                   │                   │                  └─+
           │           │                       │                       │                   │                   ├─ibus-engine-sim(171+
           │           │                       │                       │                   │                   ├─{ibus-daemon}(1582)
           │           │                       │                       │                   │                   └─{ibus-daemon}(1588)
           │           │                       │                       │                   ├─{gnome-shell}(1499)
           │           │                       │                       │                   ├─{gnome-shell}(1500)
           │           │                       │                       │                   ├─{gnome-shell}(1502)
           │           │                       │                       │                   ├─{gnome-shell}(1550)
           │           │                       │                       │                   ├─{gnome-shell}(1551)
           │           │                       │                       │                   ├─{gnome-shell}(1552)
           │           │                       │                       │                   ├─{gnome-shell}(1553)
           │           │                       │                       │                   ├─{gnome-shell}(1554)
           │           │                       │                       │                   └─{gnome-shell}(1555)
           │           │                       │                       ├─gsd-a11y-keyboa(1619)─┬─{gsd-a11y-keyboa}(1630)
           │           │                       │                       │                       ├─{gsd-a11y-keyboa}(1631)
           │           │                       │                       │                       └─{gsd-a11y-keyboa}(1675)
           │           │                       │                       ├─gsd-a11y-settin(1620)─┬─{gsd-a11y-settin}(1627)
           │           │                       │                       │                       ├─{gsd-a11y-settin}(1629)
           │           │                       │                       │                       └─{gsd-a11y-settin}(1670)
           │           │                       │                       ├─gsd-clipboard(1623)─┬─{gsd-clipboard}(1634)
           │           │                       │                       │                     └─{gsd-clipboard}(1635)
           │           │                       │                       ├─gsd-color(1626)─┬─{gsd-color}(1643)
           │           │                       │                       │                 ├─{gsd-color}(1644)
           │           │                       │                       │                 └─{gsd-color}(1645)
           │           │                       │                       ├─gsd-datetime(1628)─┬─{gsd-datetime}(1639)
           │           │                       │                       │                    └─{gsd-datetime}(1640)
           │           │                       │                       ├─gsd-housekeepin(1632)─┬─{gsd-housekeepin}(1637)
           │           │                       │                       │                       └─{gsd-housekeepin}(1642)
           │           │                       │                       ├─gsd-keyboard(1633)─┬─{gsd-keyboard}(1649)
           │           │                       │                       │                    ├─{gsd-keyboard}(1650)
           │           │                       │                       │                    └─{gsd-keyboard}(1652)
           │           │                       │                       ├─gsd-media-keys(1636)─┬─{gsd-media-keys}(1676)
           │           │                       │                       │                      ├─{gsd-media-keys}(1678)
           │           │                       │                       │                      └─{gsd-media-keys}(1688)
           │           │                       │                       ├─gsd-mouse(1641)─┬─{gsd-mouse}(1648)
           │           │                       │                       │                 └─{gsd-mouse}(1653)
           │           │                       │                       ├─gsd-power(1646)─┬─{gsd-power}(1681)
           │           │                       │                       │                 ├─{gsd-power}(1684)
           │           │                       │                       │                 └─{gsd-power}(1696)
           │           │                       │                       ├─gsd-print-notif(1647)─┬─{gsd-print-notif}(1659)
           │           │                       │                       │                       └─{gsd-print-notif}(1660)
           │           │                       │                       ├─gsd-rfkill(1651)─┬─{gsd-rfkill}(1657)
           │           │                       │                       │                  └─{gsd-rfkill}(1668)
           │           │                       │                       ├─gsd-screensaver(1654)─┬─{gsd-screensaver}(1661)
           │           │                       │                       │                       └─{gsd-screensaver}(1667)
           │           │                       │                       ├─gsd-sharing(1656)─┬─{gsd-sharing}(1663)
           │           │                       │                       │                   ├─{gsd-sharing}(1664)
           │           │                       │                       │                   └─{gsd-sharing}(1666)
           │           │                       │                       ├─gsd-smartcard(1658)─┬─{gsd-smartcard}(1674)
           │           │                       │                       │                     ├─{gsd-smartcard}(1683)
           │           │                       │                       │                     ├─{gsd-smartcard}(1690)
           │           │                       │                       │                     └─{gsd-smartcard}(1706)
           │           │                       │                       ├─gsd-sound(1665)─┬─{gsd-sound}(1689)
           │           │                       │                       │                 ├─{gsd-sound}(1691)
           │           │                       │                       │                 └─{gsd-sound}(1700)
           │           │                       │                       ├─gsd-wacom(1613)─┬─{gsd-wacom}(1621)
           │           │                       │                       │                 └─{gsd-wacom}(1625)
           │           │                       │                       ├─gsd-xsettings(1615)─┬─{gsd-xsettings}(1622)
           │           │                       │                       │                     ├─{gsd-xsettings}(1624)
           │           │                       │                       │                     └─{gsd-xsettings}(1677)
           │           │                       │                       ├─{gnome-session-b}(1444)
           │           │                       │                       ├─{gnome-session-b}(1445)
           │           │                       │                       └─{gnome-session-b}(1463)
           │           │                       ├─{gdm-session-wor}(1277)
           │           │                       └─{gdm-session-wor}(1280)
           │           ├─{gdm}(1048)
           │           ├─{gdm}(1049)
           │           └─{gdm}(1118)
           ├─gssproxy(716)─┬─{gssproxy}(727)
           │               ├─{gssproxy}(728)
           │               ├─{gssproxy}(729)
           │               ├─{gssproxy}(731)
           │               └─{gssproxy}(742)
           ├─ibus-portal(1591)─┬─{ibus-portal}(1594)
           │                   └─{ibus-portal}(1595)
           ├─ibus-x11(1587)─┬─{ibus-x11}(1596)
           │                └─{ibus-x11}(1598)
           ├─java(2044)─┬─{java}(2046)
           │            ├─{java}(2047)
           │            ├─{java}(2048)
           │            ├─{java}(2049)
           │            ├─{java}(2050)
           │            ├─{java}(2051)
           │            ├─{java}(2052)
           │            ├─{java}(2053)
           │            ├─{java}(2054)
           │            ├─{java}(2060)
           │            ├─{java}(2062)
           │            ├─{java}(2092)
           │            ├─{java}(2108)
           │            ├─{java}(2109)
           │            ├─{java}(2110)
           │            ├─{java}(2111)
           │            ├─{java}(2112)
           │            ├─{java}(2113)
           │            ├─{java}(2114)
           │            ├─{java}(2115)
           │            ├─{java}(2116)
           │            ├─{java}(2117)
           │            ├─{java}(2133)
           │            ├─{java}(2239)
           │            ├─{java}(2244)
           │            ├─{java}(2245)
           │            ├─{java}(2271)
           │            ├─{java}(2273)
           │            ├─{java}(2275)
           │            ├─{java}(2278)
           │            ├─{java}(2281)
           │            ├─{java}(2284)
           │            ├─{java}(2292)
           │            ├─{java}(2293)
           │            ├─{java}(2294)
           │            ├─{java}(2295)
           │            ├─{java}(2296)
           │            ├─{java}(2297)
           │            ├─{java}(2298)
           │            ├─{java}(2300)
           │            ├─{java}(2301)
           │            ├─{java}(2302)
           │            ├─{java}(2303)
           │            ├─{java}(2304)
           │            ├─{java}(2305)
           │            ├─{java}(2306)
           │            ├─{java}(2311)
           │            ├─{java}(2312)
           │            ├─{java}(2313)
           │            ├─{java}(2314)
           │            ├─{java}(2315)
           │            └─{java}(3888)
           ├─java(2177)─┬─{java}(2179)
           │            ├─{java}(2180)
           │            ├─{java}(2181)
           │            ├─{java}(2182)
           │            ├─{java}(2183)
           │            ├─{java}(2184)
           │            ├─{java}(2185)
           │            ├─{java}(2186)
           │            ├─{java}(2187)
           │            ├─{java}(2237)
           │            ├─{java}(2240)
           │            ├─{java}(2246)
           │            ├─{java}(2250)
           │            ├─{java}(2276)
           │            ├─{java}(2279)
           │            ├─{java}(2282)
           │            ├─{java}(2286)
           │            ├─{java}(2288)
           │            ├─{java}(2299)
           │            ├─{java}(2316)
           │            ├─{java}(2317)
           │            ├─{java}(2318)
           │            ├─{java}(2319)
           │            ├─{java}(2320)
           │            ├─{java}(2321)
           │            ├─{java}(2322)
           │            ├─{java}(2323)
           │            ├─{java}(2324)
           │            ├─{java}(2325)
           │            ├─{java}(2326)
           │            ├─{java}(2327)
           │            ├─{java}(2328)
           │            ├─{java}(2329)
           │            ├─{java}(2330)
           │            ├─{java}(2331)
           │            ├─{java}(2332)
           │            ├─{java}(2333)
           │            ├─{java}(2334)
           │            ├─{java}(2335)
           │            ├─{java}(2336)
           │            ├─{java}(2337)
           │            ├─{java}(2338)
           │            ├─{java}(2340)
           │            ├─{java}(2344)
           │            ├─{java}(2355)
           │            ├─{java}(3310)
           │            └─{java}(6152)
           ├─java(2501)─┬─{java}(2503)
           │            ├─{java}(2504)
           │            ├─{java}(2505)
           │            ├─{java}(2506)
           │            ├─{java}(2507)
           │            ├─{java}(2508)
           │            ├─{java}(2509)
           │            ├─{java}(2510)
           │            ├─{java}(2511)
           │            ├─{java}(2524)
           │            ├─{java}(2525)
           │            ├─{java}(2526)
           │            ├─{java}(2555)
           │            ├─{java}(2556)
           │            ├─{java}(2557)
           │            ├─{java}(2558)
           │            ├─{java}(2559)
           │            ├─{java}(2560)
           │            ├─{java}(2561)
           │            ├─{java}(2562)
           │            ├─{java}(2563)
           │            ├─{java}(2564)
           │            ├─{java}(2565)
           │            ├─{java}(2566)
           │            ├─{java}(2567)
           │            ├─{java}(2568)
           │            ├─{java}(2569)
           │            ├─{java}(2570)
           │            ├─{java}(2571)
           │            ├─{java}(2572)
           │            ├─{java}(2573)
           │            ├─{java}(2574)
           │            ├─{java}(2575)
           │            ├─{java}(2576)
           │            ├─{java}(2577)
           │            ├─{java}(2578)
           │            ├─{java}(2579)
           │            ├─{java}(2580)
           │            ├─{java}(2581)
           │            ├─{java}(2582)
           │            ├─{java}(2583)
           │            ├─{java}(2584)
           │            ├─{java}(2585)
           │            ├─{java}(2586)
           │            ├─{java}(2587)
           │            ├─{java}(2588)
           │            ├─{java}(2589)
           │            ├─{java}(2590)
           │            ├─{java}(2591)
           │            ├─{java}(2592)
           │            ├─{java}(2593)
           │            ├─{java}(2594)
           │            ├─{java}(2595)
           │            ├─{java}(2596)
           │            ├─{java}(2597)
           │            ├─{java}(2598)
           │            ├─{java}(2599)
           │            ├─{java}(2600)
           │            ├─{java}(2601)
           │            ├─{java}(2602)
           │            ├─{java}(2603)
           │            ├─{java}(2604)
           │            ├─{java}(2605)
           │            ├─{java}(2606)
           │            ├─{java}(2607)
           │            ├─{java}(2608)
           │            ├─{java}(2609)
           │            ├─{java}(2610)
           │            ├─{java}(2611)
           │            ├─{java}(2612)
           │            ├─{java}(2613)
           │            ├─{java}(2614)
           │            ├─{java}(2630)
           │            ├─{java}(2700)
           │            └─{java}(37263)
           ├─java(2689)─┬─{java}(2691)
           │            ├─{java}(2692)
           │            ├─{java}(2693)
           │            ├─{java}(2694)
           │            ├─{java}(2695)
           │            ├─{java}(2696)
           │            ├─{java}(2697)
           │            ├─{java}(2698)
           │            ├─{java}(2699)
           │            ├─{java}(2711)
           │            ├─{java}(2712)
           │            ├─{java}(2713)
           │            ├─{java}(2716)
           │            ├─{java}(2717)
           │            ├─{java}(2718)
           │            ├─{java}(2719)
           │            ├─{java}(2720)
           │            ├─{java}(2721)
           │            ├─{java}(2722)
           │            ├─{java}(2723)
           │            ├─{java}(2724)
           │            ├─{java}(2725)
           │            ├─{java}(2726)
           │            ├─{java}(2727)
           │            ├─{java}(2728)
           │            ├─{java}(2729)
           │            ├─{java}(2730)
           │            ├─{java}(2731)
           │            ├─{java}(2732)
           │            ├─{java}(2733)
           │            ├─{java}(2734)
           │            ├─{java}(2735)
           │            ├─{java}(2736)
           │            ├─{java}(2737)
           │            ├─{java}(2738)
           │            ├─{java}(2739)
           │            ├─{java}(2740)
           │            ├─{java}(2741)
           │            ├─{java}(2742)
           │            ├─{java}(2743)
           │            ├─{java}(2744)
           │            ├─{java}(2745)
           │            ├─{java}(2746)
           │            ├─{java}(2748)
           │            ├─{java}(2749)
           │            ├─{java}(2750)
           │            ├─{java}(2751)
           │            ├─{java}(2753)
           │            └─{java}(46236)
           ├─ksmtuned(783)───sleep(46234)
           ├─libvirtd(1022)─┬─{libvirtd}(1054)
           │                ├─{libvirtd}(1055)
           │                ├─{libvirtd}(1056)
           │                ├─{libvirtd}(1057)
           │                ├─{libvirtd}(1058)
           │                ├─{libvirtd}(1059)
           │                ├─{libvirtd}(1060)
           │                ├─{libvirtd}(1061)
           │                ├─{libvirtd}(1062)
           │                ├─{libvirtd}(1063)
           │                ├─{libvirtd}(1077)
           │                ├─{libvirtd}(1078)
           │                ├─{libvirtd}(1079)
           │                ├─{libvirtd}(1080)
           │                ├─{libvirtd}(1081)
           │                └─{libvirtd}(1095)
           ├─lsmd(709)
           ├─lvmetad(490)
           ├─master(1258)─┬─pickup(45310)
           │              └─qmgr(1276)
           ├─mysqld(1510)─┬─{mysqld}(1532)
           │              ├─{mysqld}(1539)
           │              ├─{mysqld}(1540)
           │              ├─{mysqld}(1541)
           │              ├─{mysqld}(1542)
           │              ├─{mysqld}(1543)
           │              ├─{mysqld}(1544)
           │              ├─{mysqld}(1545)
           │              ├─{mysqld}(1546)
           │              ├─{mysqld}(1547)
           │              ├─{mysqld}(1548)
           │              ├─{mysqld}(1549)
           │              ├─{mysqld}(1557)
           │              ├─{mysqld}(1558)
           │              ├─{mysqld}(1559)
           │              ├─{mysqld}(1560)
           │              ├─{mysqld}(1561)
           │              ├─{mysqld}(1562)
           │              ├─{mysqld}(1563)
           │              ├─{mysqld}(1564)
           │              ├─{mysqld}(1565)
           │              ├─{mysqld}(1566)
           │              ├─{mysqld}(1567)
           │              ├─{mysqld}(1568)
           │              ├─{mysqld}(1569)
           │              ├─{mysqld}(1570)
           │              ├─{mysqld}(2922)
           │              ├─{mysqld}(2924)
           │              ├─{mysqld}(3218)
           │              ├─{mysqld}(3230)
           │              ├─{mysqld}(20729)
           │              ├─{mysqld}(20733)
           │              ├─{mysqld}(20736)
           │              ├─{mysqld}(20737)
           │              └─{mysqld}(20751)
           ├─packagekitd(1608)─┬─{packagekitd}(1612)
           │                   └─{packagekitd}(1614)
           ├─polkitd(682)─┬─{polkitd}(710)
           │              ├─{polkitd}(744)
           │              ├─{polkitd}(748)
           │              ├─{polkitd}(759)
           │              └─{polkitd}(769)
           ├─pulseaudio(1529)─┬─{pulseaudio}(1533)
           │                  └─{pulseaudio}(1536)
           ├─rngd(723)
           ├─rpcbind(686)
           ├─rsyslogd(1010)─┬─{rsyslogd}(1029)
           │                └─{rsyslogd}(1039)
           ├─rtkit-daemon(683)─┬─{rtkit-daemon}(746)
           │                   └─{rtkit-daemon}(747)
           ├─smartd(717)
           ├─sshd(1004)───sshd(37296)───sshd(37308)───bash(37311)───pstree(46237)
           ├─systemd-journal(466)
           ├─systemd-logind(719)
           ├─systemd-udevd(502)
           ├─tuned(1005)─┬─{tuned}(1472)
           │             ├─{tuned}(1473)
           │             ├─{tuned}(1479)
           │             └─{tuned}(1498)
           ├─udisksd(685)─┬─{udisksd}(698)
           │              ├─{udisksd}(754)
           │              ├─{udisksd}(787)
           │              └─{udisksd}(788)
           ├─upowerd(1511)─┬─{upowerd}(1512)
           │               └─{upowerd}(1513)
           ├─vmtoolsd(715)───{vmtoolsd}(763)
           ├─wpa_supplicant(1610)
           └─xdg-permission-(1574)─┬─{xdg-permission-}(1577)
                                   └─{xdg-permission-}(1579)

--------------------------------------

<-->39.netstat 显示网络状态和端口占用信息

1）基本语法
netstat -anp | grep 进程号 （功能描述：查看该进程网络信息）
netstat –nlp | grep 端口号 （功能描述：查看网络端口号占用情况）

2）选项说明

选项 功能
-a 显示所有正在监听（listen）和未监听的套接字（socket）
-n 拒绝显示别名，能显示数字的全部转化成数字
-l 仅列出在监听的服务状态
-p 表示显示哪个进程在调用

3）案例实操
（1）通过进程号查看sshd进程的网络信息
[root@hadoop101 hadoop-2.7.2]# netstat -anp | grep sshd
tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN
951/sshd
tcp 0 0 192.168.202.100:22 192.168.202.1:57741
ESTABLISHED 3380/sshd: root@pts
tcp 0 52 192.168.202.100:22 192.168.202.1:57783
ESTABLISHED 3568/sshd: root@pts
tcp 0 0 192.168.202.100:22 192.168.202.1:57679
ESTABLISHED 3142/sshd: root@pts
tcp6 0 0 :::22 :::* LISTEN
951/sshd
unix 2 [ ] DGRAM 39574 3568/sshd:
root@pts
unix 2 [ ] DGRAM 37452 3142/sshd:
root@pts
unix 2 [ ] DGRAM 48651 3380/sshd:
root@pts
unix 3 [ ] STREAM CONNECTED 21224 951/sshd
（2）查看某端口号是否被占用
[root@hadoop101 桌面]# netstat -nltp | grep 22
tcp 0 0 192.168.122.1:53 0.0.0.0:* LISTEN
1324/dnsmasq
tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN
951/sshd
tcp6 0 0 :::22 :::* LISTEN
951/sshd

<-->40.crontab 系统定时任务

1）重新启动 crond 服务
[root@hadoop101 ~]# systemctl restart crond

1）基本语法
crontab [选项]

2）选项说明

选项 功能
-e 编辑 crontab 定时任务
-l 查询 crontab 任务
-r 删除当前用户所有的 crontab 任务

3）参数说明
[root@hadoop101 ~]# crontab -e 
（1）进入 crontab 编辑界面。会打开 vim 编辑你的工作。
* * * * * 执行的任务
项目 含义 范围
第一个“*” 一小时当中的第几分钟 0-59
第二个“*” 一天当中的第几小时 0-23
第三个“*” 一个月当中的第几天 1-31
第四个“*” 一年当中的第几月 1-12
第五个“*” 一周当中的星期几 0-7 （0 和7 都代表星期日）

（2）特殊符号
表 7-43
特殊符号 含义
* 代表任何时间。比如第一个“*”就代表一小时中每分钟都执行一次的意思。
， 代表不连续的时间。比如“0 8,12,16 * * * 命令”，
就代表在每天的 8 点 0 分，12 点 0 分，16 点0 分都执行一次命令- 代表连续的时间范围。
比如“0 5 * * 1-6 命令”，代表在周一到周六的凌晨 5 点 0 分执行命令*/n 代表每隔多久执行一次。
比如“*/10 * * * * 命令”，代表每隔 10 分钟就执行一遍命令

（3）特定时间执行命令

时间 含义
45 22 * * * 命令 每天 22 点 45 分执行命令
0 17 * * 1 命令 每周 1 的 17 点 0 分执行命令
0 5 1,15 * * 命令 每月 1 号和 15 号的凌晨 5 点 0 分执行命令
40 4 * * 1-5 命令 每周一到周五的凌晨 4 点 40 分执行命令
*/10 4 * * * 命令 每天的凌晨 4 点，每隔 10 分钟执行一次命令
0 0 1,15 * 1 命令 每月 1 号和 15 号，每周 1 的 0 点 0 分都会执行命令。
注意：星期几和几号最好不要同时出现，因为他们定义的都是天。非常容易让管理员混乱。

4）案例实操
（1）每隔 1 分钟，向/root/bailongma.txt 文件中添加一个 11 的数字
*/1 * * * * /bin/echo ”11” >> /root/bailongma.txt

-----其他进程命令

4 top 实时监控系统进程状态

1）基本命令
top [选项]

--------------------------- <-->09.软件包管理类命令-----------------------

RPM 概述
RPM（RedHat Package Manager），RedHat软件包管理工具，类似windows里面的setup.exe
是Linux这系列操作系统里面的打包安装工具，它虽然是RedHat的标志，但理念是通用的。
RPM包的名称格式
Apache-1.3.23-11.i386.rpm
- “apache” 软件名称
- “1.3.23-11”软件的版本号，主版本和此版本
- “i386”是软件所运行的硬件平台，Intel 32位处理器的统称
- “rpm”文件扩展名，代表RPM包

<-->41.rpm 软件管理工具

8.1.2 RPM 查询命令（rpm -qa）
1）基本语法
rpm -qa （功能描述：查询所安装的所有 rpm 软件包）
2）经验技巧
由于软件包比较多，一般都会采取过滤。rpm -qa | grep rpm软件包
3）案例实操
（1）查询firefox软件安装情况
[root@hadoop101 Packages]# rpm -qa |grep firefox
firefox-45.0.1-1.el6.centos.x86_64

8.1.3 RPM 卸载命令（rpm -e）
1）基本语法
（1）rpm -e RPM软件包
（2） rpm -e --nodeps 软件包
2）选项说明
选项 功能
-e 卸载软件包
--nodeps 卸载软件时，不检查依赖。
这样的话，那些使用该软件包的软件在此之后可能就不能正常工作了。
3）案例实操
（1）卸载firefox软件
[root@hadoop101 Packages]# rpm -e firefox

8.1.4 RPM 安装命令（rpm -ivh）
1）基本语法
rpm -ivh RPM 包全名
2）选项说明
选项 功能
-i install，安装
-v --verbose，显示详细信息
-h --hash，进度条
--nodeps 安装前不检查依赖
3）案例实操
（1）安装firefox软件
[root@hadoop101 Packages]# pwd
/run/media/root/CentOS 7 x86_64/Packages
[root@hadoop101 Packages]# rpm -ivh firefox-45.0.1-1.el6.centos.x86_64.rpm
warning: firefox-45.0.1-1.el6.centos.x86_64.rpm: Header V3 RSA/SHA1
Signature, key ID c105b9de: NOKEY
Preparing... ###########################################
[100%]
1:firefox ###########################################
[100%]

--------<-->YUM 仓库配置----------------------
 
YUM 概述
YUM（全称为 Yellow dog Updater, Modified）
是一个在 Fedora 和RedHat 以及CentOS中的 Shell 前端软件包管理器。
基于 RPM 包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，
并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装.

YUM类似于我们开发java中的maven工具，可以从镜像网站上下载应用程序并直接安装

<-->42.YUM的常用命令
1）基本语法
yum [选项] [参数]
2）选项说明
选项 功能
-y 对所有提问都回答“yes”
3）参数说明
参数 功能
install 安装 rpm 软件包
update 更新 rpm 软件包
check-update 检查是否有可用的更新 rpm 软件包
remove 删除指定的 rpm 软件包
list 显示软件包信息
clean 清理 yum 过期的缓存
deplist 显示 yum 软件包的所有依赖关系
4）案例实操实操
（1）采用 yum 方式安装 firefox
[root@hadoop101 ~]#yum -y install firefox

8.2.3 修改网络 YUM 源
默认的系统 YUM 源，需要连接国外 apache 网站，网速比较慢，可以修改关联的网络YUM 源为国内镜像的网站，比如网易 163,aliyun 等
1）安装 wget, wget 用来从指定的 URL 下载文件
[root@hadoop101 ~] yum install wget
2）在/etc/yum.repos.d/目录下，备份默认的 repos 文件, [root@hadoop101 yum.repos.d] pwd
/etc/yum.repos.d
[root@hadoop101 yum.repos.d] cp CentOS-Base.repo CentOS-Base
.repo.backup
3）下载网易 163 或者是 aliyun 的 repos 文件,任选其一，如图 8-2
[root@hadoop101 yum.repos.d] wget
http://mirrors.aliyun.com/repo/Centos-7.repo //阿里云
[root@hadoop101 yum.repos.d] wget
http://mirrors.163.com/.help/CentOS7-Base-163.repo //网易 163
4）使用下载好的 repos 文件替换默认的 repos 文件
例如:用 CentOS7-Base-163.repo 替换 CentOS-Base.repo
[root@hadoop101 yum.repos.d]# mv CentOS7-Base-163.repo CentOS-Base.repo
5）清理旧缓存数据，缓存新数据
[root@hadoop101 yum.repos.d]#yum clean all
[root@hadoop101 yum.repos.d]#yum makecache
yum makecache 就是把服务器的包信息下载到本地电脑缓存起来6）测试
[root@hadoop101 yum.repos.d]# yum list | grep firefox
[root@hadoop101 ~]#yum -y install firefox

---------------------------------------<-->其他常用命令-----------------------------------------------------
<-->43.sz(下载)和rz(上传) 部分远程登录系统不支持
借助XShell，使用linux命令sz可以很方便的将服务器上的文件下载到本地，使用rz命令则是把本地文件上传到服务器。
sz中的s意为send（发送），告诉客户端，我（服务器）要发送文件 send to cilent，就等同于客户端在下载。
rz中的r意为received（接收），告诉客户端，我（服务器）要接收文件 received by cilent，就等同于客户端在上传。

打开xshell，
①检查是否已经安装了上传下载的命令，#rpm -qa |grep lrzsz，如下表示已经安装了。
[root@mjy logs]# rpm -qa |grep lrzsz
lrzsz-0.12.20-27.1.el6.i686
 如果未安装有，可使用yum安装，#yum install  lrzsz -y

------下载 sz
sz用法：
下载一个文件
sz filename
下载多个文件
sz filename1 filename2
下载dir目录下的所有文件，不包含dir下的文件夹
sz dir/*

-----------上传 rz
rz用法：
输入rz回车后，会出现文件选择对话框，选择需要上传文件，
一次可以指定多个文件，上传到服务器的路径为当前执行rz命令的目录。
一次可以指定多个文件，上传到服务器的路径为当前执行rz命令的目录。

<-->44.sh命令
常见选项：

-c  :command 后面跟一个字符串，这个字符串可以是我们平常执行的任何命令，有参数选项时一定要用引号括起来
-x  :后面跟shell脚本，可以详细的显示shell脚本的执行信息
sh -c "ls -l"等价于 ls -l

<-->45.export
export 功能说明：设置或显示环境变量。


语　　法：export [-fnp][变量名称]=[变量设置值]
补充说明：在shell中执行程序时，shell会提供一组环境变量。export可新增，修改或删除环境变量，供后续执行的程序使用。
export的效力仅限于该次登陆操作。
参　　数：
　-f 　代表[变量名称]中为函数名称。
　-n 　删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。
　-p 　列出所有的shell赋予程序的环境变量。

用户登录到Linux系统后，系统将启动一个用户shell。在这个shell中，可以使用shell命
或声明变量，也可以创建并运行shell脚本程序。运行shell脚本程序时，系统将创建一个子shell。
此时，系统中将有两个shell，一个是登录时系统启动的shell，另一个是系统为运行脚本程序创建
的shell。当一个脚本程序运行完毕，脚本shell将终止，返回到执行该脚本之前的shell。
从这种意义上来说，用户可以有许多 shell，每个shell都是由某个shell（称为父shell）派生的。
在子shell中定义的变量只在该子shell内有效。如果在一个shell脚本程序中定义了一个变量，
当该脚本程序运行时，这个定义的变量只是该脚本程序内的一个局部变量，其他的shell不能引用它，
要使某个变量的值可以在其他shell中被改变，可以使用export命令对已定义的变量进行输出。
export命令将使系统在创建每一个新的shell时，定义这个变量的一个拷贝。
这个过程称之为变量输出。

结论：
1、执行脚本时是在一个子shell环境运行的，脚本执行完后该子shell自动退出；
2、一个shell中的系统环境变量会被复制到子shell中（用export定义的变量）；
3、一个shell中的系统环境变量只对该shell或者它的子shell有效，该shell结束时变量消失
（并不能返回到父shell中）。
3、不用export定义的变量只对该shell有效，对子shell也是无效的。
为什么一个脚本直接执行和用source执行不一行呢？manual原文是这样的：

Read and execute commands from filename in the current shell environment and
return the exit status of the last command executed from filename.

直接执行一个脚本文件是在一个子shell中运行的，而source则是在当前shell环境中运行的。

<-->46.source

source命令：
source命令也称为“点命令”，也就是一个点符号（.）,是bash的内部命令。
功能：使Shell读入指定的Shell程序文件并依次执行文件中的所有语句
source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录。
用法：
source filename 或 . filename
source命令(从 C Shell 而来)是bash shell的内置命令;点命令(.)，就是个点符号(从Bourne Shell而来)是source的另一名称。

source filename 与 sh filename 及./filename执行脚本的区别在那里呢？
1.当shell脚本具有可执行权限时，用sh filename与./filename执行脚本是没有区别得。./filename是因为当前目录没有在PATH中，
所有"."是用来表示当前目录的。
2.sh filename 重新建立一个子shell，在子shell中执行脚本里面的语句，该子shell继承父shell的环境变量，
但子shell新建的、改变的变量不会被带回父shell，除非使用export。
3.source filename：这个命令其实只是简单地读取脚本里面的语句依次在当前shell里面执行，
没有建立新的子shell。那么脚本里面所有新建、改变变量的语句都会保存在当前shell里面。

举例说明：
1.新建一个test.sh脚本，内容为:A=1
2.然后使其可执行chmod +x test.sh
3.运行sh test.sh后，echo $A，显示为空，因为A=1并未传回给当前shell
4.运行./test.sh后，也是一样的效果
5.运行source test.sh 或者 . test.sh，然后echo $A，则会显示1，说明A=1的变量在当前shell中

---------------------------------------<-->剪切和脚本处理类命令-----------------------------------------------------

<-->01.cut